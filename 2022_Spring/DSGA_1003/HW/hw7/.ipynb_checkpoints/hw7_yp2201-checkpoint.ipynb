{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "7aeba0d9",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: (Node L2 dist node) Max rel error for partial deriv w.r.t. a is 5.555018106715376e-10.\r\n",
      "DEBUG: (Node L2 dist node) Max rel error for partial deriv w.r.t. b is 7.846443893968331e-10.\r\n",
      "DEBUG: (Node L2 dist node) Max rel error for partial deriv w.r.t. a is 6.831390843302146e-09.\r\n",
      "DEBUG: (Node L2 dist node) Max rel error for partial deriv w.r.t. b is 6.831390843302146e-09.\r\n",
      "DEBUG: (Node L2 dist node) Max rel error for partial deriv w.r.t. a is 1.1180220551889923e-06.\r\n",
      "DEBUG: (Node L2 dist node) Max rel error for partial deriv w.r.t. b is 1.1180220551889923e-06.\r\n",
      ".DEBUG: (Node affine node) Max rel error for partial deriv w.r.t. x is 4.293668135518121e-09.\r\n",
      "DEBUG: (Node affine node) Max rel error for partial deriv w.r.t. w is 2.565255271019285e-09.\r\n",
      "DEBUG: (Node affine node) Max rel error for partial deriv w.r.t. b is 5.838672027299854e-10.\r\n",
      ".DEBUG: (Parameter w) Max rel error for partial deriv 3.9325684906842595e-08.\r\n",
      "DEBUG: (Parameter b) Max rel error for partial deriv 1.690156865548506e-09.\r\n",
      ".\r\n",
      "----------------------------------------------------------------------\r\n",
      "Ran 3 tests in 0.006s\r\n",
      "\r\n",
      "OK\r\n"
     ]
    }
   ],
   "source": [
    "# %run linear_regression.t.py\n",
    "!python3 linear_regression.t.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "a1df11da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  0 : average objective value= 0.6016721167054945\n",
      "Epoch  5 : average objective value= 0.22436612154491942\n",
      "Epoch  10 : average objective value= 0.1847361845940021\n",
      "Epoch  15 : average objective value= 0.14573259108449274\n",
      "Epoch  20 : average objective value= 0.1528726318560972\n",
      "Epoch  25 : average objective value= 0.14160757492864057\n",
      "Epoch  30 : average objective value= 0.11980548459863163\n",
      "Epoch  35 : average objective value= 0.13680139943770242\n",
      "Epoch  40 : average objective value= 0.11370433571825789\n",
      "Epoch  45 : average objective value= 0.11280145616797388\n",
      "Epoch  50 : average objective value= 0.10981644271207813\n",
      "Epoch  55 : average objective value= 0.09314424852923231\n",
      "Epoch  60 : average objective value= 0.11741763669836741\n",
      "Epoch  65 : average objective value= 0.09078068409093928\n",
      "Epoch  70 : average objective value= 0.10318804348786224\n",
      "Epoch  75 : average objective value= 0.09445302520088474\n",
      "Epoch  80 : average objective value= 0.09913177046699864\n",
      "Epoch  85 : average objective value= 0.08798383010706791\n",
      "Epoch  90 : average objective value= 0.0867310295245314\n",
      "Epoch  95 : average objective value= 0.08946316043592818\n",
      "Epoch  100 : average objective value= 0.09626856750791536\n",
      "Epoch  105 : average objective value= 0.08165373516849565\n",
      "Epoch  110 : average objective value= 0.0852385855914875\n",
      "Epoch  115 : average objective value= 0.08258261937405954\n",
      "Epoch  120 : average objective value= 0.08281219820755797\n",
      "Epoch  125 : average objective value= 0.0864193847021396\n",
      "Epoch  130 : average objective value= 0.0688444913087858\n",
      "Epoch  135 : average objective value= 0.0784578026106325\n",
      "Epoch  140 : average objective value= 0.07518784046085666\n",
      "Epoch  145 : average objective value= 0.07359756112211933\n",
      "Epoch  150 : average objective value= 0.07104855736988003\n",
      "Epoch  155 : average objective value= 0.06303840784129365\n",
      "Epoch  160 : average objective value= 0.07965459174884323\n",
      "Epoch  165 : average objective value= 0.059390226650084754\n",
      "Epoch  170 : average objective value= 0.07080557503769437\n",
      "Epoch  175 : average objective value= 0.06604005764090712\n",
      "Epoch  180 : average objective value= 0.07010771467051356\n",
      "Epoch  185 : average objective value= 0.06406310835854594\n",
      "Epoch  190 : average objective value= 0.06724237332328353\n",
      "Epoch  195 : average objective value= 0.06332890407360087\n",
      "Epoch  200 : average objective value= 0.06242838748997414\n",
      "Epoch  205 : average objective value= 0.06248456445218289\n",
      "Epoch  210 : average objective value= 0.0672245351522362\n",
      "Epoch  215 : average objective value= 0.059678558617363785\n",
      "Epoch  220 : average objective value= 0.060306541004332165\n",
      "Epoch  225 : average objective value= 0.06427756859391368\n",
      "Epoch  230 : average objective value= 0.06263833583476762\n",
      "Epoch  235 : average objective value= 0.05335782315806067\n",
      "Epoch  240 : average objective value= 0.05808861180296014\n",
      "Epoch  245 : average objective value= 0.05411227101020535\n",
      "Epoch  250 : average objective value= 0.05245556926596972\n",
      "Epoch  255 : average objective value= 0.052621677243681615\n",
      "Epoch  260 : average objective value= 0.05803340068546046\n",
      "Epoch  265 : average objective value= 0.052599860791937986\n",
      "Epoch  270 : average objective value= 0.05118730119737382\n",
      "Epoch  275 : average objective value= 0.05548184902275418\n",
      "Epoch  280 : average objective value= 0.05332685310471882\n",
      "Epoch  285 : average objective value= 0.0523405018929241\n",
      "Epoch  290 : average objective value= 0.05611653662355603\n",
      "Epoch  295 : average objective value= 0.05483989447116883\n",
      "Epoch  300 : average objective value= 0.051465089843982244\n",
      "Epoch  305 : average objective value= 0.05324618443347571\n",
      "Epoch  310 : average objective value= 0.04989976997898373\n",
      "Epoch  315 : average objective value= 0.04847126778615522\n",
      "Epoch  320 : average objective value= 0.054009853356238986\n",
      "Epoch  325 : average objective value= 0.039534462033665126\n",
      "Epoch  330 : average objective value= 0.04740874281385238\n",
      "Epoch  335 : average objective value= 0.04269577846989691\n",
      "Epoch  340 : average objective value= 0.04383369913339744\n",
      "Epoch  345 : average objective value= 0.04371725644927439\n",
      "Epoch  350 : average objective value= 0.045690902271011115\n",
      "Epoch  355 : average objective value= 0.0458840031880308\n",
      "Epoch  360 : average objective value= 0.045562835922911014\n",
      "Epoch  365 : average objective value= 0.04800513560915649\n",
      "Epoch  370 : average objective value= 0.04288094978630554\n",
      "Epoch  375 : average objective value= 0.03888158210422872\n",
      "Epoch  380 : average objective value= 0.038491585364581096\n",
      "Epoch  385 : average objective value= 0.04612600461364785\n",
      "Epoch  390 : average objective value= 0.043537775365662654\n",
      "Epoch  395 : average objective value= 0.045712619012910405\n",
      "Epoch  400 : average objective value= 0.03468255217158606\n",
      "Epoch  405 : average objective value= 0.0401922430471058\n",
      "Epoch  410 : average objective value= 0.03869216795676818\n",
      "Epoch  415 : average objective value= 0.04161196594097517\n",
      "Epoch  420 : average objective value= 0.03665592937737455\n",
      "Epoch  425 : average objective value= 0.03416256858663897\n",
      "Epoch  430 : average objective value= 0.039392209993888316\n",
      "Epoch  435 : average objective value= 0.03798049627726525\n",
      "Epoch  440 : average objective value= 0.040098554333224345\n",
      "Epoch  445 : average objective value= 0.041511118207357686\n",
      "Epoch  450 : average objective value= 0.03716391064413672\n",
      "Epoch  455 : average objective value= 0.03567258917213725\n",
      "Epoch  460 : average objective value= 0.029664052595438587\n",
      "Epoch  465 : average objective value= 0.03743580165195407\n",
      "Epoch  470 : average objective value= 0.041395736247233875\n",
      "Epoch  475 : average objective value= 0.03412873688429223\n",
      "Epoch  480 : average objective value= 0.03627282877609948\n",
      "Epoch  485 : average objective value= 0.03565042726139216\n",
      "Epoch  490 : average objective value= 0.03729530035616611\n",
      "Epoch  495 : average objective value= 0.03414704776933346\n",
      "Epoch  500 : average objective value= 0.032848392765774455\n",
      "Epoch  505 : average objective value= 0.03468427350565038\n",
      "Epoch  510 : average objective value= 0.036034742483759444\n",
      "Epoch  515 : average objective value= 0.035214054673119395\n",
      "Epoch  520 : average objective value= 0.031515835131436874\n",
      "Epoch  525 : average objective value= 0.0336764628662716\n",
      "Epoch  530 : average objective value= 0.03818161028444498\n",
      "Epoch  535 : average objective value= 0.03243667128451978\n",
      "Epoch  540 : average objective value= 0.030534538837101173\n",
      "Epoch  545 : average objective value= 0.032614869728002115\n",
      "Epoch  550 : average objective value= 0.03315648229296996\n",
      "Epoch  555 : average objective value= 0.03129470226134108\n",
      "Epoch  560 : average objective value= 0.03096287868378325\n",
      "Epoch  565 : average objective value= 0.031195107139949364\n",
      "Epoch  570 : average objective value= 0.03274289625980075\n",
      "Epoch  575 : average objective value= 0.027520786828116622\n",
      "Epoch  580 : average objective value= 0.033018231362782965\n",
      "Epoch  585 : average objective value= 0.0315850799361971\n",
      "Epoch  590 : average objective value= 0.03148769758198617\n",
      "Epoch  595 : average objective value= 0.029132301641746787\n",
      "Epoch  600 : average objective value= 0.03015900172320712\n",
      "Epoch  605 : average objective value= 0.030570216545489127\n",
      "Epoch  610 : average objective value= 0.03138148119569746\n",
      "Epoch  615 : average objective value= 0.02996175003802083\n",
      "Epoch  620 : average objective value= 0.02706178423825275\n",
      "Epoch  625 : average objective value= 0.027042819777520478\n",
      "Epoch  630 : average objective value= 0.031182622376786213\n",
      "Epoch  635 : average objective value= 0.029188512430610113\n",
      "Epoch  640 : average objective value= 0.026708307106257802\n",
      "Epoch  645 : average objective value= 0.031529172998773974\n",
      "Epoch  650 : average objective value= 0.030181887642516055\n",
      "Epoch  655 : average objective value= 0.024936030550431615\n",
      "Epoch  660 : average objective value= 0.02802939057536564\n",
      "Epoch  665 : average objective value= 0.028414145193091267\n",
      "Epoch  670 : average objective value= 0.025805402438966656\n",
      "Epoch  675 : average objective value= 0.031604605273230855\n",
      "Epoch  680 : average objective value= 0.02622750927642591\n",
      "Epoch  685 : average objective value= 0.02467398419235004\n",
      "Epoch  690 : average objective value= 0.02506337173782974\n",
      "Epoch  695 : average objective value= 0.027022789402541464\n",
      "Epoch  700 : average objective value= 0.02465961918667742\n",
      "Epoch  705 : average objective value= 0.024549814312627993\n",
      "Epoch  710 : average objective value= 0.025822047065851197\n",
      "Epoch  715 : average objective value= 0.027012404321682667\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  720 : average objective value= 0.02414075086797635\n",
      "Epoch  725 : average objective value= 0.021695291718473023\n",
      "Epoch  730 : average objective value= 0.02680561950584497\n",
      "Epoch  735 : average objective value= 0.024199908851369356\n",
      "Epoch  740 : average objective value= 0.02335525780984401\n",
      "Epoch  745 : average objective value= 0.023817462011197117\n",
      "Epoch  750 : average objective value= 0.028044807696991914\n",
      "Epoch  755 : average objective value= 0.025336652429095143\n",
      "Epoch  760 : average objective value= 0.025464517145504226\n",
      "Epoch  765 : average objective value= 0.024950153352017737\n",
      "Epoch  770 : average objective value= 0.023996917145570874\n",
      "Epoch  775 : average objective value= 0.021227545024116917\n",
      "Epoch  780 : average objective value= 0.02196867359971883\n",
      "Epoch  785 : average objective value= 0.024038031072776647\n",
      "Epoch  790 : average objective value= 0.02420328374844437\n",
      "Epoch  795 : average objective value= 0.022346087106159568\n",
      "Epoch  800 : average objective value= 0.02293539478052129\n",
      "Epoch  805 : average objective value= 0.023402307719664207\n",
      "Epoch  810 : average objective value= 0.019667160962862834\n",
      "Epoch  815 : average objective value= 0.021961103771374536\n",
      "Epoch  820 : average objective value= 0.024213683863026296\n",
      "Epoch  825 : average objective value= 0.024432425469430145\n",
      "Epoch  830 : average objective value= 0.020139483159851267\n",
      "Epoch  835 : average objective value= 0.022703285169242457\n",
      "Epoch  840 : average objective value= 0.0213376133275469\n",
      "Epoch  845 : average objective value= 0.02070096256649891\n",
      "Epoch  850 : average objective value= 0.020494486446543118\n",
      "Epoch  855 : average objective value= 0.021987570312758154\n",
      "Epoch  860 : average objective value= 0.023229439353502725\n",
      "Epoch  865 : average objective value= 0.02089804042800098\n",
      "Epoch  870 : average objective value= 0.020258214161542464\n",
      "Epoch  875 : average objective value= 0.021178050914496382\n",
      "Epoch  880 : average objective value= 0.018769002906641588\n",
      "Epoch  885 : average objective value= 0.018158596663093506\n",
      "Epoch  890 : average objective value= 0.020053138023900546\n",
      "Epoch  895 : average objective value= 0.020940148364497136\n",
      "Epoch  900 : average objective value= 0.021189717576022463\n",
      "Epoch  905 : average objective value= 0.020976453153742847\n",
      "Epoch  910 : average objective value= 0.016176113873567564\n",
      "Epoch  915 : average objective value= 0.022405400475856495\n",
      "Epoch  920 : average objective value= 0.020452792786994644\n",
      "Epoch  925 : average objective value= 0.02074775190981236\n",
      "Epoch  930 : average objective value= 0.01902664963256165\n",
      "Epoch  935 : average objective value= 0.020203469902315606\n",
      "Epoch  940 : average objective value= 0.01791372431362149\n",
      "Epoch  945 : average objective value= 0.016040904450304545\n",
      "Epoch  950 : average objective value= 0.016637053280313504\n",
      "Epoch  955 : average objective value= 0.019303421663440377\n",
      "Epoch  960 : average objective value= 0.017974135671418544\n",
      "Epoch  965 : average objective value= 0.018077925253520925\n",
      "Epoch  970 : average objective value= 0.016844559840005123\n",
      "Epoch  975 : average objective value= 0.019652073565761194\n",
      "Epoch  980 : average objective value= 0.018678209700628147\n",
      "Epoch  985 : average objective value= 0.019504750507331237\n",
      "Epoch  990 : average objective value= 0.017356898241936817\n",
      "Epoch  995 : average objective value= 0.016538851874344177\n",
      "Figure(640x480)\n"
     ]
    }
   ],
   "source": [
    "!python3 linear_regression.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b8b6755",
   "metadata": {},
   "source": [
    "### 1. Complete the class L2NormPenaltyNode in nodes.py. If your code is correct, you should be able to pass test L2NormPenaltyNode in ridge regression.t.py. Please attach a screenshot that shows the test results for this question."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "392f96ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: (Node l2 norm node) Max rel error for partial deriv w.r.t. w is 2.40251835204311e-09.\r\n",
      ".DEBUG: (Node sum node) Max rel error for partial deriv w.r.t. a is 5.838671711157847e-10.\r\n",
      "DEBUG: (Node sum node) Max rel error for partial deriv w.r.t. b is 1.6365788111231558e-09.\r\n",
      ".DEBUG: (Parameter w) Max rel error for partial deriv 2.176183360312541e-09.\r\n",
      "DEBUG: (Parameter b) Max rel error for partial deriv 3.0678572477687213e-10.\r\n",
      ".\r\n",
      "----------------------------------------------------------------------\r\n",
      "Ran 3 tests in 0.001s\r\n",
      "\r\n",
      "OK\r\n"
     ]
    }
   ],
   "source": [
    "!python3 ridge_regression.t.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5224ba6f",
   "metadata": {},
   "source": [
    "### 2. Complete the class SumNode in nodes.py. If your code is correct, you should be able to pass test SumNode in ridge regression.t.py. Please attach a screenshot that shows the test results for this question."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "5a52ddd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: (Node l2 norm node) Max rel error for partial deriv w.r.t. w is 4.83304267387949e-09.\r\n",
      ".DEBUG: (Node sum node) Max rel error for partial deriv w.r.t. a is 5.263558043709814e-10.\r\n",
      "DEBUG: (Node sum node) Max rel error for partial deriv w.r.t. b is 5.838672237759561e-10.\r\n",
      ".DEBUG: (Parameter w) Max rel error for partial deriv 1.6418297217822408e-09.\r\n",
      "DEBUG: (Parameter b) Max rel error for partial deriv 6.361722608755208e-10.\r\n",
      ".\r\n",
      "----------------------------------------------------------------------\r\n",
      "Ran 3 tests in 0.001s\r\n",
      "\r\n",
      "OK\r\n"
     ]
    }
   ],
   "source": [
    "!python3 ridge_regression.t.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cfb745e",
   "metadata": {},
   "source": [
    "### 3. Implement ridge regression with w regularized and b unregularized. Do this by completing the init method in ridge regression.py, using the classes created above. When complete, you should be able to pass the tests in ridge regression.t.py. Report the average square error on the training set for the parameter settings given in the main() function."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a46430f",
   "metadata": {},
   "source": [
    "### Ans)\n",
    "- Param setting 1: Epoch  1950 : Ave objective= 0.30416333498507436  Ave training loss:  0.19975259892554026\n",
    "- Param setting 2: Epoch  450 : Ave objective= 0.05068003196007712  Ave training loss:  0.0440921497856686"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "7b0a44c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: (Node l2 norm node) Max rel error for partial deriv w.r.t. w is 1.5793975691809997e-09.\r\n",
      ".DEBUG: (Node sum node) Max rel error for partial deriv w.r.t. a is 5.838671350819793e-10.\r\n",
      "DEBUG: (Node sum node) Max rel error for partial deriv w.r.t. b is 5.838671350819793e-10.\r\n",
      ".DEBUG: (Parameter w) Max rel error for partial deriv 1.4461955971802003e-08.\r\n",
      "DEBUG: (Parameter b) Max rel error for partial deriv 7.521670660093729e-10.\r\n",
      ".\r\n",
      "----------------------------------------------------------------------\r\n",
      "Ran 3 tests in 0.001s\r\n",
      "\r\n",
      "OK\r\n"
     ]
    }
   ],
   "source": [
    "!python3 ridge_regression.t.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "8807903a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  0 : Ave objective= 1.5397692262354772  Ave training loss:  0.773882852716091\n",
      "Epoch  50 : Ave objective= 0.32710982471117167  Ave training loss:  0.24182064265098216\n",
      "Epoch  100 : Ave objective= 0.3163552159608086  Ave training loss:  0.21168126665443704\n",
      "Epoch  150 : Ave objective= 0.3141367150068179  Ave training loss:  0.2036773846247195\n",
      "Epoch  200 : Ave objective= 0.3132144999949803  Ave training loss:  0.200399383407836\n",
      "Epoch  250 : Ave objective= 0.3122867760951629  Ave training loss:  0.19873252694349475\n",
      "Epoch  300 : Ave objective= 0.3124644337730294  Ave training loss:  0.19800689583549608\n",
      "Epoch  350 : Ave objective= 0.3115115933530548  Ave training loss:  0.19783047086865047\n",
      "Epoch  400 : Ave objective= 0.31127602561238515  Ave training loss:  0.1975496011090101\n",
      "Epoch  450 : Ave objective= 0.3092228793008847  Ave training loss:  0.1993226690076808\n",
      "Epoch  500 : Ave objective= 0.31047091949265054  Ave training loss:  0.19755085672728956\n",
      "Epoch  550 : Ave objective= 0.31001560370885184  Ave training loss:  0.19744092366626706\n",
      "Epoch  600 : Ave objective= 0.31021339602090414  Ave training loss:  0.1977211922939273\n",
      "Epoch  650 : Ave objective= 0.3095276922207127  Ave training loss:  0.19787497851446723\n",
      "Epoch  700 : Ave objective= 0.3092125103565232  Ave training loss:  0.19776349340722332\n",
      "Epoch  750 : Ave objective= 0.3091329379052249  Ave training loss:  0.1981325389078443\n",
      "Epoch  800 : Ave objective= 0.30876908624801835  Ave training loss:  0.1979105068412471\n",
      "Epoch  850 : Ave objective= 0.3073076584006622  Ave training loss:  0.19827662393246123\n",
      "Epoch  900 : Ave objective= 0.30778739060465626  Ave training loss:  0.19794078584745495\n",
      "Epoch  950 : Ave objective= 0.30680525643584444  Ave training loss:  0.19859196881072755\n",
      "Epoch  1000 : Ave objective= 0.30599950057551284  Ave training loss:  0.19933054834768874\n",
      "Epoch  1050 : Ave objective= 0.3064185340140233  Ave training loss:  0.19998200723830858\n",
      "Epoch  1100 : Ave objective= 0.3074044565870049  Ave training loss:  0.1981598065661778\n",
      "Epoch  1150 : Ave objective= 0.3066501065365863  Ave training loss:  0.19891279044668675\n",
      "Epoch  1200 : Ave objective= 0.3066283669087145  Ave training loss:  0.19893176668173193\n",
      "Epoch  1250 : Ave objective= 0.3066170375699567  Ave training loss:  0.19909065863683925\n",
      "Epoch  1300 : Ave objective= 0.3065163290081598  Ave training loss:  0.19873206458207626\n",
      "Epoch  1350 : Ave objective= 0.3052268346995633  Ave training loss:  0.1988605052798221\n",
      "Epoch  1400 : Ave objective= 0.30639633378596653  Ave training loss:  0.19885198912791804\n",
      "Epoch  1450 : Ave objective= 0.30533510972074746  Ave training loss:  0.19889918735687495\n",
      "Epoch  1500 : Ave objective= 0.30509608324355053  Ave training loss:  0.1992086035995897\n",
      "Epoch  1550 : Ave objective= 0.30619956579919977  Ave training loss:  0.19894998655477322\n",
      "Epoch  1600 : Ave objective= 0.3057485785783776  Ave training loss:  0.1990621412382704\n",
      "Epoch  1650 : Ave objective= 0.3054076642044352  Ave training loss:  0.19979989514480226\n",
      "Epoch  1700 : Ave objective= 0.3054380428588343  Ave training loss:  0.19924823377040402\n",
      "Epoch  1750 : Ave objective= 0.30518565102775874  Ave training loss:  0.1998109765222668\n",
      "Epoch  1800 : Ave objective= 0.30542024692988834  Ave training loss:  0.19943023167942908\n",
      "Epoch  1850 : Ave objective= 0.30286929120806494  Ave training loss:  0.20083304360117624\n",
      "Epoch  1900 : Ave objective= 0.3044370169886135  Ave training loss:  0.19986403544732625\n",
      "Epoch  1950 : Ave objective= 0.30416333498507436  Ave training loss:  0.19975259892554026\n",
      "Epoch  0 : Ave objective= 0.6831868441647562  Ave training loss:  0.41474726450845645\n",
      "Epoch  50 : Ave objective= 0.1178153688385627  Ave training loss:  0.10594259162888632\n",
      "Epoch  100 : Ave objective= 0.10035638630071304  Ave training loss:  0.08708395223033598\n",
      "Epoch  150 : Ave objective= 0.08501851410887146  Ave training loss:  0.07790740468137543\n",
      "Epoch  200 : Ave objective= 0.07501148672587422  Ave training loss:  0.06427205386910566\n",
      "Epoch  250 : Ave objective= 0.06793453829714871  Ave training loss:  0.0583967778477586\n",
      "Epoch  300 : Ave objective= 0.06156154955236004  Ave training loss:  0.05614295209748719\n",
      "Epoch  350 : Ave objective= 0.05799974446518799  Ave training loss:  0.05108533237386188\n",
      "Epoch  400 : Ave objective= 0.052964781335534734  Ave training loss:  0.04997282714912114\n",
      "Epoch  450 : Ave objective= 0.05068003196007712  Ave training loss:  0.0440921497856686\n",
      "Figure(640x480)\n"
     ]
    }
   ],
   "source": [
    "!python3 ridge_regression.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "763cab31",
   "metadata": {},
   "source": [
    "### 9. Complete the class AffineNode in nodes.py. Be sure to propagate the gradient with respect to x as well, since when we stack these layers, x will itself be the output of another node that depends on our optimization parameters. If your code is correct, you should be able to pass test AffineNode in mlp regression.t.py. Please attach a screenshot that shows the test results for this question."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "2a32c051",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: (Node affine) Max rel error for partial deriv w.r.t. W is 5.096644672744053e-09.\r\n",
      "DEBUG: (Node affine) Max rel error for partial deriv w.r.t. x is 2.406972643688512e-09.\r\n",
      "DEBUG: (Node affine) Max rel error for partial deriv w.r.t. b is 1.6365788136702465e-09.\r\n",
      ".DEBUG: (Node tanh) Max rel error for partial deriv w.r.t. a is 1.9763106114969626e-09.\r\n",
      ".DEBUG: (Parameter W1) Max rel error for partial deriv 1.0183356954301854e-06.\r\n",
      "DEBUG: (Parameter b1) Max rel error for partial deriv 1.4064319110385487e-07.\r\n",
      "DEBUG: (Parameter w2) Max rel error for partial deriv 3.9176596430029976e-10.\r\n",
      "DEBUG: (Parameter b2) Max rel error for partial deriv 1.2719200164908194e-09.\r\n",
      ".\r\n",
      "----------------------------------------------------------------------\r\n",
      "Ran 3 tests in 0.003s\r\n",
      "\r\n",
      "OK\r\n"
     ]
    }
   ],
   "source": [
    "!python3 mlp_regression.t.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e4d1c85",
   "metadata": {},
   "source": [
    "### 10. Complete the class TanhNode in nodes.py. As you’ll recall, d tanh(x) = 1−tanh2 x. Note that in the forward pass, we’ll already have computed tanh of the input and stored it in self.out. So make sure to use self.out and not recalculate it in the backward pass. If your code is correct, you should be able to pass test TanhNode in mlp regression.t.py. Please attach a screenshot that shows the test results for this question."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "5212697a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: (Node affine) Max rel error for partial deriv w.r.t. W is 7.20890634703604e-09.\r\n",
      "DEBUG: (Node affine) Max rel error for partial deriv w.r.t. x is 2.7104551533182506e-09.\r\n",
      "DEBUG: (Node affine) Max rel error for partial deriv w.r.t. b is 2.8043131637107875e-09.\r\n",
      ".DEBUG: (Node tanh) Max rel error for partial deriv w.r.t. a is 1.3223247573520519e-08.\r\n",
      ".DEBUG: (Parameter W1) Max rel error for partial deriv 1.0234941457123598e-07.\r\n",
      "DEBUG: (Parameter b1) Max rel error for partial deriv 7.845227157989209e-09.\r\n",
      "DEBUG: (Parameter w2) Max rel error for partial deriv 2.1094707366925755e-09.\r\n",
      "DEBUG: (Parameter b2) Max rel error for partial deriv 3.7026688293685366e-11.\r\n",
      ".\r\n",
      "----------------------------------------------------------------------\r\n",
      "Ran 3 tests in 0.003s\r\n",
      "\r\n",
      "OK\r\n"
     ]
    }
   ],
   "source": [
    "!python3 mlp_regression.t.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c2c9769",
   "metadata": {},
   "source": [
    "### 11. Implement an MLP by completing the skeleton code in mlp regression.py and making use of the nodes above. Your code should pass the tests provided in mlp regression.t.py. Note that to break the symmetry of the problem, we initialize our weights to small random values, rather than all zeros, as we often do for convex optimization problems. Run the MLP for the two settings given in the main() function and report the average training error. Note that with an MLP, we can take the original scalar as input, in the hopes that it will learn nonlinear features on its own, using the hidden layers. In practice, it is quite challenging to get such a neural network to fit as well as one where we provide features."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6257979f",
   "metadata": {},
   "source": [
    "### Ans)\n",
    "- Param setting 1: Epoch  4950 : Ave objective= 0.2517892021591148  Ave training loss:  0.2466271830311671\n",
    "- Param setting 2: Epoch  450 : Ave objective= 0.04810750384711343  Ave training loss:  0.04353498392690943"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "15d6173d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: (Node affine) Max rel error for partial deriv w.r.t. W is 2.1649804391653896e-08.\r\n",
      "DEBUG: (Node affine) Max rel error for partial deriv w.r.t. x is 1.3375169571128545e-09.\r\n",
      "DEBUG: (Node affine) Max rel error for partial deriv w.r.t. b is 5.838672493090357e-10.\r\n",
      ".DEBUG: (Node tanh) Max rel error for partial deriv w.r.t. a is 2.2602113877588296e-09.\r\n",
      ".DEBUG: (Parameter W1) Max rel error for partial deriv 1.4024483631179634e-06.\r\n",
      "DEBUG: (Parameter b1) Max rel error for partial deriv 5.84622549909781e-08.\r\n",
      "DEBUG: (Parameter w2) Max rel error for partial deriv 2.365268344555844e-09.\r\n",
      "DEBUG: (Parameter b2) Max rel error for partial deriv 5.358513545257987e-10.\r\n",
      ".\r\n",
      "----------------------------------------------------------------------\r\n",
      "Ran 3 tests in 0.003s\r\n",
      "\r\n",
      "OK\r\n"
     ]
    }
   ],
   "source": [
    "!python3 mlp_regression.t.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "aa30e7af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  0 : Ave objective= 3.1372299638583443  Ave training loss:  2.7245175473602563\n",
      "Epoch  50 : Ave objective= 0.9452827547222492  Ave training loss:  0.9434803938707458\n",
      "Epoch  100 : Ave objective= 0.944597313967138  Ave training loss:  0.942822701516118\n",
      "Epoch  150 : Ave objective= 0.9381889958983242  Ave training loss:  0.9361438894605034\n",
      "Epoch  200 : Ave objective= 0.8916882438726752  Ave training loss:  0.8886559118333026\n",
      "Epoch  250 : Ave objective= 0.7980854393680246  Ave training loss:  0.7942088354802567\n",
      "Epoch  300 : Ave objective= 0.7724258503770075  Ave training loss:  0.7684601989119884\n",
      "Epoch  350 : Ave objective= 0.7685327106133726  Ave training loss:  0.7641927975870911\n",
      "Epoch  400 : Ave objective= 0.763972076795527  Ave training loss:  0.7596854265533888\n",
      "Epoch  450 : Ave objective= 0.7579723903031386  Ave training loss:  0.7536772950048044\n",
      "Epoch  500 : Ave objective= 0.7500308900529531  Ave training loss:  0.7463946022241141\n",
      "Epoch  550 : Ave objective= 0.741382445192695  Ave training loss:  0.7375212560624566\n",
      "Epoch  600 : Ave objective= 0.7319598218695657  Ave training loss:  0.7279270036486416\n",
      "Epoch  650 : Ave objective= 0.7218429409667476  Ave training loss:  0.7179801963034373\n",
      "Epoch  700 : Ave objective= 0.7121488259748504  Ave training loss:  0.7083443962992614\n",
      "Epoch  750 : Ave objective= 0.7029590750401717  Ave training loss:  0.699751411596027\n",
      "Epoch  800 : Ave objective= 0.6958487803346894  Ave training loss:  0.692052695503854\n",
      "Epoch  850 : Ave objective= 0.6889848733086522  Ave training loss:  0.6856461268648576\n",
      "Epoch  900 : Ave objective= 0.683879745732657  Ave training loss:  0.6801700706099212\n",
      "Epoch  950 : Ave objective= 0.6790914054345432  Ave training loss:  0.6753773905606997\n",
      "Epoch  1000 : Ave objective= 0.67461416742754  Ave training loss:  0.6707258376554553\n",
      "Epoch  1050 : Ave objective= 0.6699336924956628  Ave training loss:  0.6659213768109037\n",
      "Epoch  1100 : Ave objective= 0.6646267092078818  Ave training loss:  0.6604827925894096\n",
      "Epoch  1150 : Ave objective= 0.6579386665123366  Ave training loss:  0.6540229819406158\n",
      "Epoch  1200 : Ave objective= 0.6501049574286468  Ave training loss:  0.645781411078141\n",
      "Epoch  1250 : Ave objective= 0.6389820380359533  Ave training loss:  0.6351594840782552\n",
      "Epoch  1300 : Ave objective= 0.6267422981715194  Ave training loss:  0.621182101479781\n",
      "Epoch  1350 : Ave objective= 0.6096922308487539  Ave training loss:  0.6036611921755903\n",
      "Epoch  1400 : Ave objective= 0.5871592113114565  Ave training loss:  0.5824255122647926\n",
      "Epoch  1450 : Ave objective= 0.5624650944166429  Ave training loss:  0.5567388798911057\n",
      "Epoch  1500 : Ave objective= 0.5334773507892872  Ave training loss:  0.5271552072117036\n",
      "Epoch  1550 : Ave objective= 0.5025000506339409  Ave training loss:  0.4949900446872924\n",
      "Epoch  1600 : Ave objective= 0.46940493836227515  Ave training loss:  0.46171599056179075\n",
      "Epoch  1650 : Ave objective= 0.43713580801508223  Ave training loss:  0.4299963778156122\n",
      "Epoch  1700 : Ave objective= 0.40902192533686366  Ave training loss:  0.4012777421883999\n",
      "Epoch  1750 : Ave objective= 0.385804876645516  Ave training loss:  0.37760247658554313\n",
      "Epoch  1800 : Ave objective= 0.365705102793051  Ave training loss:  0.35961549462492476\n",
      "Epoch  1850 : Ave objective= 0.351683459058947  Ave training loss:  0.3474298568134552\n",
      "Epoch  1900 : Ave objective= 0.34210644316097855  Ave training loss:  0.33545967155850753\n",
      "Epoch  1950 : Ave objective= 0.33452823027163686  Ave training loss:  0.3275925543488193\n",
      "Epoch  2000 : Ave objective= 0.3282618673117908  Ave training loss:  0.32365452914442655\n",
      "Epoch  2050 : Ave objective= 0.3223679791820626  Ave training loss:  0.31783521452068636\n",
      "Epoch  2100 : Ave objective= 0.3174220352828289  Ave training loss:  0.3162819481653934\n",
      "Epoch  2150 : Ave objective= 0.31638260401427687  Ave training loss:  0.31104928131556453\n",
      "Epoch  2200 : Ave objective= 0.3078067316413647  Ave training loss:  0.3137402691559692\n",
      "Epoch  2250 : Ave objective= 0.3103645459990607  Ave training loss:  0.3060268561982318\n",
      "Epoch  2300 : Ave objective= 0.3063719806836269  Ave training loss:  0.30245369935501615\n",
      "Epoch  2350 : Ave objective= 0.30553988924993947  Ave training loss:  0.2989518240028619\n",
      "Epoch  2400 : Ave objective= 0.30223629399473106  Ave training loss:  0.2967551426217347\n",
      "Epoch  2450 : Ave objective= 0.30111091864612566  Ave training loss:  0.2946057520108414\n",
      "Epoch  2500 : Ave objective= 0.2972195347636188  Ave training loss:  0.29653611614464426\n",
      "Epoch  2550 : Ave objective= 0.2959008719871427  Ave training loss:  0.29102919956233825\n",
      "Epoch  2600 : Ave objective= 0.2952988536904669  Ave training loss:  0.28928764239503624\n",
      "Epoch  2650 : Ave objective= 0.2904116279271233  Ave training loss:  0.28945620081521317\n",
      "Epoch  2700 : Ave objective= 0.2918994084928246  Ave training loss:  0.2858979083693339\n",
      "Epoch  2750 : Ave objective= 0.2891811102756042  Ave training loss:  0.28600056133549917\n",
      "Epoch  2800 : Ave objective= 0.2883583944867868  Ave training loss:  0.28334604983320405\n",
      "Epoch  2850 : Ave objective= 0.2870277036680218  Ave training loss:  0.28164845375505715\n",
      "Epoch  2900 : Ave objective= 0.28527478927146316  Ave training loss:  0.280196223652486\n",
      "Epoch  2950 : Ave objective= 0.2841469393749212  Ave training loss:  0.2788841975957578\n",
      "Epoch  3000 : Ave objective= 0.2830719266073899  Ave training loss:  0.27766341632748226\n",
      "Epoch  3050 : Ave objective= 0.28259083447436256  Ave training loss:  0.27646689792880214\n",
      "Epoch  3100 : Ave objective= 0.27998975377232954  Ave training loss:  0.2751209948047446\n",
      "Epoch  3150 : Ave objective= 0.27593578147398357  Ave training loss:  0.2762787253893217\n",
      "Epoch  3200 : Ave objective= 0.2782746813204589  Ave training loss:  0.272790200164311\n",
      "Epoch  3250 : Ave objective= 0.27713097089708427  Ave training loss:  0.2718446148160518\n",
      "Epoch  3300 : Ave objective= 0.27558458186121887  Ave training loss:  0.2707793205030399\n",
      "Epoch  3350 : Ave objective= 0.27402507212977695  Ave training loss:  0.2702771055554609\n",
      "Epoch  3400 : Ave objective= 0.2722596224322322  Ave training loss:  0.26935754895607666\n",
      "Epoch  3450 : Ave objective= 0.2716932905233509  Ave training loss:  0.2674264337047009\n",
      "Epoch  3500 : Ave objective= 0.27148088897309497  Ave training loss:  0.2664526570935234\n",
      "Epoch  3550 : Ave objective= 0.2706738838997602  Ave training loss:  0.26572174717643415\n",
      "Epoch  3600 : Ave objective= 0.26896596512212634  Ave training loss:  0.2649490243063213\n",
      "Epoch  3650 : Ave objective= 0.2662092969627675  Ave training loss:  0.2659399146190705\n",
      "Epoch  3700 : Ave objective= 0.2676623316272179  Ave training loss:  0.26300289439733393\n",
      "Epoch  3750 : Ave objective= 0.26646298886883135  Ave training loss:  0.262058855151565\n",
      "Epoch  3800 : Ave objective= 0.26636619498615344  Ave training loss:  0.26123465383967887\n",
      "Epoch  3850 : Ave objective= 0.264788540439431  Ave training loss:  0.26065491165886046\n",
      "Epoch  3900 : Ave objective= 0.26455701380346824  Ave training loss:  0.26031665993292796\n",
      "Epoch  3950 : Ave objective= 0.2636415823947875  Ave training loss:  0.2595257015178095\n",
      "Epoch  4000 : Ave objective= 0.2633229290881269  Ave training loss:  0.2581811555172635\n",
      "Epoch  4050 : Ave objective= 0.2617482542039863  Ave training loss:  0.2575318073980088\n",
      "Epoch  4100 : Ave objective= 0.2615049719707205  Ave training loss:  0.256910246786964\n",
      "Epoch  4150 : Ave objective= 0.261030714994256  Ave training loss:  0.25614127832657757\n",
      "Epoch  4200 : Ave objective= 0.2598111111912403  Ave training loss:  0.25567184676696697\n",
      "Epoch  4250 : Ave objective= 0.2597343095390833  Ave training loss:  0.2548064950045585\n",
      "Epoch  4300 : Ave objective= 0.25931677249247054  Ave training loss:  0.25409771441048074\n",
      "Epoch  4350 : Ave objective= 0.25775929841751444  Ave training loss:  0.2537265947086025\n",
      "Epoch  4400 : Ave objective= 0.2577394936442572  Ave training loss:  0.25323683817130227\n",
      "Epoch  4450 : Ave objective= 0.25775575939767864  Ave training loss:  0.2522390906917334\n",
      "Epoch  4500 : Ave objective= 0.2550677168924124  Ave training loss:  0.25293630844453124\n",
      "Epoch  4550 : Ave objective= 0.25561524644844297  Ave training loss:  0.25268822429676924\n",
      "Epoch  4600 : Ave objective= 0.25522061126841444  Ave training loss:  0.2504584954429009\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  4650 : Ave objective= 0.2545288778391154  Ave training loss:  0.24991999046901595\n",
      "Epoch  4700 : Ave objective= 0.2536255336753047  Ave training loss:  0.2501975867031055\n",
      "Epoch  4750 : Ave objective= 0.25285352999966426  Ave training loss:  0.24880916351131863\n",
      "Epoch  4800 : Ave objective= 0.25310287449598295  Ave training loss:  0.24819772083835126\n",
      "Epoch  4850 : Ave objective= 0.25243128503818324  Ave training loss:  0.24773243264769146\n",
      "Epoch  4900 : Ave objective= 0.25182699918856594  Ave training loss:  0.24731332147361157\n",
      "Epoch  4950 : Ave objective= 0.2517892021591148  Ave training loss:  0.2466271830311671\n",
      "Epoch  0 : Ave objective= 3.129180955915638  Ave training loss:  2.5356880675792426\n",
      "Epoch  50 : Ave objective= 0.15198897610921253  Ave training loss:  0.14127616646666227\n",
      "Epoch  100 : Ave objective= 0.11617229196547293  Ave training loss:  0.10922815719456622\n",
      "Epoch  150 : Ave objective= 0.09689318420383945  Ave training loss:  0.09027240887919734\n",
      "Epoch  200 : Ave objective= 0.08688141536169326  Ave training loss:  0.08294853882032388\n",
      "Epoch  250 : Ave objective= 0.0723006890815104  Ave training loss:  0.06625030721858471\n",
      "Epoch  300 : Ave objective= 0.06747412845654321  Ave training loss:  0.05916509099607956\n",
      "Epoch  350 : Ave objective= 0.06223976560659244  Ave training loss:  0.053569926499627156\n",
      "Epoch  400 : Ave objective= 0.051356207027161184  Ave training loss:  0.06207849926433166\n",
      "Epoch  450 : Ave objective= 0.04810750384711343  Ave training loss:  0.04353498392690943\n",
      "Figure(640x480)\n"
     ]
    }
   ],
   "source": [
    "!python3 mlp_regression.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d09211e",
   "metadata": {},
   "source": [
    "### 12. Implement a Softmax node. We provided skeleton code for class SoftmaxNode in nodes.py. If your code is correct, you should be able to pass test SoftmaxNode in multiclass.t.py. Please attach a screenshot that shows the test results for this question."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "711dad43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: (Node softmax) Max rel error for partial deriv w.r.t. z is 3.224197197211726e-08.\n",
      ".DEBUG: (Parameter W1) Max rel error for partial deriv 0.0034522232406777017.\n",
      "DEBUG: (Parameter b1) Max rel error for partial deriv 4.931291984539323e-06.\n",
      "DEBUG: (Parameter W2) Max rel error for partial deriv 8.02572545110171e-08.\n",
      "DEBUG: (Parameter b2) Max rel error for partial deriv 2.444586428981455e-08.\n",
      ".\n",
      "----------------------------------------------------------------------\n",
      "Ran 2 tests in 0.003s\n",
      "\n",
      "OK\n"
     ]
    }
   ],
   "source": [
    "!python3 multiclass.t.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e901525f",
   "metadata": {},
   "source": [
    "### 13. Implement a negative log-likelihood loss node for multiclass classification. We provided skeleton code for class NLLNode in nodes.py. The test code for this question is combined with the test code for the next question."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "id": "e18f6f39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: (Node softmax) Max rel error for partial deriv w.r.t. z is 4.0720297226290016e-08.\r\n",
      ".DEBUG: (Parameter W1) Max rel error for partial deriv 0.003758631664432458.\r\n",
      "DEBUG: (Parameter b1) Max rel error for partial deriv 4.427123495313254e-06.\r\n",
      "DEBUG: (Parameter W2) Max rel error for partial deriv 9.513048846801781e-08.\r\n",
      "DEBUG: (Parameter b2) Max rel error for partial deriv 1.2250136576683586e-08.\r\n",
      ".\r\n",
      "----------------------------------------------------------------------\r\n",
      "Ran 2 tests in 0.003s\r\n",
      "\r\n",
      "OK\r\n"
     ]
    }
   ],
   "source": [
    "! python3 multiclass.t.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b7ae0e0",
   "metadata": {},
   "source": [
    "### 14. Implement a MLP for multiclass classification by completing the skeleton code in multiclass.py. Your code should pass the tests in test multiclass provided in multiclass.t.py. Please attach a screenshot that shows the test results for this question."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "id": "2612b6a2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: (Node softmax) Max rel error for partial deriv w.r.t. z is 2.4707612958850724e-08.\n",
      ".DEBUG: (Parameter W1) Max rel error for partial deriv 2.2246845867534564e-07.\n",
      "DEBUG: (Parameter b1) Max rel error for partial deriv 2.8713153278798485e-07.\n",
      "DEBUG: (Parameter W2) Max rel error for partial deriv 5.967296793011328e-08.\n",
      "DEBUG: (Parameter b2) Max rel error for partial deriv 1.7622812282215924e-08.\n",
      ".\n",
      "----------------------------------------------------------------------\n",
      "Ran 2 tests in 0.003s\n",
      "\n",
      "OK\n"
     ]
    }
   ],
   "source": [
    "! python3 multiclass.t.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "id": "dafb23ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  0  Ave training loss:  1.173826640097864\n",
      "Epoch  50  Ave training loss:  1.098614266195899\n",
      "Epoch  100  Ave training loss:  1.0986221645634051\n",
      "Epoch  150  Ave training loss:  1.098613562726454\n",
      "Epoch  200  Ave training loss:  1.0986136410229712\n",
      "Epoch  250  Ave training loss:  1.0986135631744594\n",
      "Epoch  300  Ave training loss:  1.0986188138298667\n",
      "Epoch  350  Ave training loss:  1.0986080992626166\n",
      "Epoch  400  Ave training loss:  1.0986176393463343\n",
      "Epoch  450  Ave training loss:  1.0986102050118365\n",
      "Epoch  500  Ave training loss:  1.0986138470209137\n",
      "Epoch  550  Ave training loss:  1.0986122212214515\n",
      "Epoch  600  Ave training loss:  1.0986165994094421\n",
      "Epoch  650  Ave training loss:  1.0986140826848703\n",
      "Epoch  700  Ave training loss:  1.0986148684954136\n",
      "Epoch  750  Ave training loss:  1.0986227325072\n",
      "Epoch  800  Ave training loss:  1.098614166197705\n",
      "Epoch  850  Ave training loss:  1.0986102419111892\n",
      "Epoch  900  Ave training loss:  1.0986107134024037\n",
      "Epoch  950  Ave training loss:  1.098610481902228\n",
      "Test set accuracy = 0.440\n"
     ]
    }
   ],
   "source": [
    "! python3 multiclass.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08081434",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
