{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "88949566",
   "metadata": {},
   "source": [
    "<p style='font-weight:bold; font-size:24px'> Data analysis project 1: Yoon Tae Park (yp2201@nyu.edu)</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "273f4807",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Before answering questions, I will import some basic libraries and create dataset from given csv file\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import stats\n",
    "\n",
    "#ignore warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "dataset = pd.read_csv('./movieReplicationSet.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c34f7326",
   "metadata": {},
   "source": [
    "<p style='font-weight:bold; font-size:18px'> 1) Are movies that are more popular (operationalized as having more ratings) rated higher than movies that are less popular? [Hint: You can do a median-split of popularity to determine high vs. low popularity movies] </p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f195cba5",
   "metadata": {},
   "source": [
    "<p style='font-weight:bold; font-size:18px'> Answer) </p>\n",
    "<p style='font-size:16px'> I can check this by conducting null hypothesis testing(which I will use for most of questions)</p>\n",
    "<p style='font-size:16px'> Hypothesis: Popular movies are rated higher than less popular movies</p>\n",
    "<p style='font-size:16px'> Null hypothesis: Popular movies are not rated higher than less popular movies</p>\n",
    "<p style='font-size:16px'> I will assume that the null hypothesis is true</p><br>\n",
    "\n",
    "<p style='font-size:16px'>  I divided movies into high-popularity movies and low-popularity movies by median. Then I've conducted Mann-Whitney U test and caclulated p-value. I am using  Mann-Whitney U test test since I am comparing 2 groups that are nonparametric, and movie ratings data is ordinal data.</p><br>\n",
    "\n",
    "<p style='font-size:16px'> p-value was relatively small(1.6971433120157929e-40) compared to significant level a=0.005</p>\n",
    "<p style='font-size:16px'> So, I rejected the null hypothesis. In english, I've concluded that popular movies are rated higher than less popular movies(below are detailed codes that follow my conclusion)</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a1bf031e",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# We don't need columns other than movie ratings, so filter by movies\n",
    "dataset_movies = dataset.iloc[:, :400]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "52e5dd2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Since popularity is determined by not null counts for each movies, \n",
    "# we need to create a new row which counts not null\n",
    "dataset_movies.loc['not_null_cnt'] = dataset_movies.notnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a3683bba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "197.5"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# now we compute median of not null counts and find that median is 197.5\n",
    "np.median(dataset_movies.loc['not_null_cnt'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5c2eb2b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a function that divides movies into high/low popular movies\n",
    "# If some movies are having exact same value as median, I won't be using those movies \n",
    "def high_low_check(x):\n",
    "    \n",
    "    if x > np.median(dataset_movies.iloc[1097]): return 'high'\n",
    "    elif x < np.median(dataset_movies.iloc[1097]): return 'low'\n",
    "    else: return 'same'\n",
    "    \n",
    "dataset_movies.loc['popular'] = dataset_movies.iloc[1097].apply(lambda x: high_low_check(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "afaf873e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "low     200\n",
       "high    200\n",
       "Name: popular, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# For this time, every movies are divided by low and high\n",
    "dataset_movies.loc['popular'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "32ff15b8",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# now let's filter movies that are popluar\n",
    "high_movie = dataset_movies.loc[:, dataset_movies.loc['popular'] == 'high'][:1097]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f628e5f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For high popular movies each, delete null values element-wise and get the mean value\n",
    "# It is because we don't know what values to be substituted\n",
    "# and we will lose a lot of statistic power if we delete null values row-wise\n",
    "# (I will use row-wise deletion for entire problems)\n",
    "high_movie_array = []\n",
    "\n",
    "for i in range(len(high_movie.columns)):\n",
    "    each_movie = high_movie.iloc[:,i]\n",
    "    each_movie = each_movie[pd.notnull(each_movie)]\n",
    "    high_movie_array.append(each_movie.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "748f2c2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Doing same thing for low popular movies as well\n",
    "low_movie = dataset_movies.loc[:, dataset_movies.loc['popular'] == 'low'][:1097]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1bdf3cc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "low_movie_array = []\n",
    "\n",
    "for i in range(len(low_movie.columns)):\n",
    "    each_movie = low_movie.iloc[:,i]\n",
    "    each_movie = each_movie[pd.notnull(each_movie)]\n",
    "    low_movie_array.append(each_movie.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a26f52e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(35404.0, 1.6971433120157929e-40)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Then, calculate p-value by using Mann-Whitney U test\n",
    "# I am using U test since I am comparing 2 groups that are nonparametric, and movie ratings data is ordinal data.\n",
    "\n",
    "# p-value was relatively small(1.6971433120157929e-40) compared to significant level a=0.005\n",
    "# reject null hypothesis that popular movies are not rated higher than less popular movies \n",
    "# and conclude that movies that are more popular rated higher than movies that are less popular\n",
    "u1, p1 = stats.mannwhitneyu(high_movie_array, low_movie_array)\n",
    "u1, p1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2be65c11",
   "metadata": {},
   "source": [
    "<p style='font-weight:bold; font-size:18px'> 2) Are movies that are newer rated differently than movies that are older? [Hint: Do a median split of year of release to contrast movies in terms of whether they are old or new] </p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa9fc63e",
   "metadata": {},
   "source": [
    "<p style='font-weight:bold; font-size:18px'> Answer) </p>\n",
    "<p style='font-size:16px'> I can check this by conducting null hypothesis testing</p>\n",
    "<p style='font-size:16px'> Hypothesis: newer movies are rated differently than older movies</p>\n",
    "<p style='font-size:16px'> Null hypothesis: newer movies are not rated differently than older movies</p><br>\n",
    "<p style='font-size:16px'> I will assume that the null hypothesis is true</p><br>\n",
    "\n",
    "<p style='font-size:16px'>  I divided movies into newer movies and older movies by median. Then I've conducted Mann-Whitney U test and caclulated p-value. I am using  Mann-Whitney U test test since I am comparing 2 groups that are nonparametric, and movie ratings data is ordinal data.</p><br>\n",
    "\n",
    "<p style='font-size:16px'> p-value was relatively big(0.16654749319603956) compared to significant level a=0.005</p>\n",
    "\n",
    "<p style='font-size:16px'> So, we don't do anything because we already assumed that the null hypothesis is true. In english, newer movies are not rated differently than older movies.(below are detailed codes that follow my conclusion)</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "a0c1ad95",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Starting from 'dataset_movies' variable (which contains movie ratings only)\n",
    "# We need to find years for each movies. I've parsed columns and extracted year data\n",
    "dataset_movies.loc['year'] = dataset_movies.columns.str[-5:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "d4867076",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['2003'], dtype='object')"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# By parsing as below, we can get year data from movie name. \n",
    "dataset_movies.columns.str[-5:-1][:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "24ae150b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rambo: First Blood Part II doesn't have year data \n",
    "# I'll drop this column, as this movie is the only movie that doesn't have year data\n",
    "dataset_movies_v2 = dataset_movies.drop('Rambo: First Blood Part II', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "8aaacf37",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1999.0"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculating median year value for entire movies. Median year is 1999\n",
    "dataset_movies_v2.loc['year'].median()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "5ebb510c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classify movies into new/old/same\n",
    "\n",
    "def old_new_check(x):\n",
    "    \n",
    "    if x > dataset_movies_v2.loc['year'].median(): return 'new'\n",
    "    elif x < dataset_movies_v2.loc['year'].median(): return 'old'\n",
    "    else: return 'same'\n",
    "    \n",
    "dataset_movies_v2.loc['old_new_check'] = dataset_movies_v2.loc['year'].apply(lambda x: old_new_check(int(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "7df2a6cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "old     196\n",
       "new     174\n",
       "same     29\n",
       "Name: old_new_check, dtype: int64"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Note that I won't be using 'same' movies, since those have median values (Not old, Not new)\n",
    "dataset_movies_v2.loc['old_new_check'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "219a72d3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Filter by new movies\n",
    "new_movies = dataset_movies_v2.loc[:, dataset_movies_v2.loc['old_new_check'] == 'new'][:1097]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "491c6270",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new array and append each new movie's mean rating\n",
    "new_movie_array = []\n",
    "\n",
    "for i in range(len(new_movies.columns)):\n",
    "    each_movie = new_movies.iloc[:,i]\n",
    "    each_movie = each_movie[pd.notnull(each_movie)]\n",
    "    new_movie_array.append(each_movie.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "3d19d298",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter by old movies\n",
    "old_movies = dataset_movies_v2.loc[:, dataset_movies_v2.loc['old_new_check'] == 'old'][:1097]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "df3e05fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new array and append each old movie's mean rating\n",
    "old_movie_array = []\n",
    "\n",
    "for i in range(len(old_movies.columns)):\n",
    "    each_movie = old_movies.iloc[:,i]\n",
    "    each_movie = each_movie[pd.notnull(each_movie)]\n",
    "    old_movie_array.append(each_movie.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "a3116db3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(18473.0, 0.16654749319603956)"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Then, calculate p-value by using Mann-Whitney U test\n",
    "# I am using U test since I am comparing 2 groups that are nonparametric, and movie ratings data is ordinal data.\n",
    "\n",
    "# p-value was relatively big(0.16654749319603956) compared to significant level a=0.005\n",
    "# So, we don't do anything because we already assumed that the null hypothesis is true\n",
    "# In english, newer movies are not rated differently than older movies\n",
    "\n",
    "u1, p1 = stats.mannwhitneyu(new_movie_array, old_movie_array)\n",
    "u1, p1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b11abfed",
   "metadata": {},
   "source": [
    "<p style='font-weight:bold; font-size:18px'>3) Is enjoyment of ‘Shrek (2001)’ gendered, i.e. do male and female viewers rate it differently?</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd6ad265",
   "metadata": {},
   "source": [
    "<p style='font-weight:bold; font-size:18px'> Answer) </p>\n",
    "<p style='font-size:16px'> I can check this by conducting null hypothesis testing</p>\n",
    "<p style='font-size:16px'> Hypothesis: Shrek (2001) was rated differently by gender</p>\n",
    "<p style='font-size:16px'> Null hypothesis: Shrek (2001) was not rated differently by gender</p><br>\n",
    "<p style='font-size:16px'> I will assume that the null hypothesis is true</p><br>\n",
    "\n",
    "<p style='font-size:16px'>  I divided Sherk (2001) movie by male and female. Then I've conducted Mann-Whitney U test and caclulated p-value. I am using  Mann-Whitney U test test since I am comparing 2 groups that are nonparametric, and movie ratings data is ordinal data.</p><br>\n",
    "\n",
    "<p style='font-size:16px'> p-value was relatively big(0.050536625925559006) compared to significant level a=0.005</p>\n",
    "\n",
    "\n",
    "<p style='font-size:16px'> So, we don't do anything because we already assumed that the null hypothesis is true. In english, Shrek (2001) was not rated differently by gender.(below are detailed codes that follow my conclusion)</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4bb05f46",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0    807\n",
       "2.0    260\n",
       "3.0      6\n",
       "Name: Gender identity (1 = female; 2 = male; 3 = self-described), dtype: int64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking gender distribution\n",
    "# I didn't used 3 value, since we cannot decide self-described.\n",
    "dataset.iloc[:, 474].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9891d53d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter by female rows and shrek column\n",
    "# Also delete null values element-wise\n",
    "female_shrek = dataset[dataset.iloc[:, 474] == 1.0]['Shrek (2001)']\n",
    "female_shrek = female_shrek[pd.notnull(female_shrek)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "fc2c05f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter by male rows and shrek column\n",
    "# Also delete null values element-wise\n",
    "male_shrek = dataset[dataset.iloc[:, 474] == 2.0]['Shrek (2001)']\n",
    "male_shrek = male_shrek[pd.notnull(male_shrek)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6a233f14",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(96830.5, 0.050536625925559006)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Then, calculate p-value by using Mann-Whitney U test\n",
    "# I am using U test since I am comparing 2 groups that are nonparametric, and movie ratings data is ordinal data.\n",
    "\n",
    "# p-value was relatively big(0.050536625925559006) compared to significant level a=0.005\n",
    "# So, we don't do anything because we already assumed that the null hypothesis is true\n",
    "# In english, Shrek (2001) was not rated differently by gender.\n",
    "\n",
    "u1, p1 = stats.mannwhitneyu(female_shrek, male_shrek)\n",
    "u1, p1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b2527ec",
   "metadata": {},
   "source": [
    "<p style='font-weight:bold; font-size:18px'>4) What proportion of movies are rated differently by male and female viewers?</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb277299",
   "metadata": {},
   "source": [
    "<p style='font-weight:bold; font-size:18px'> Answer) </p>\n",
    "\n",
    "<p style='font-size:16px'> I will apply below null hypothesis testing to each movies and calculate proportion of movies that have relatively small p-value. If p-value is relatively small, I can conclude that given movie is rated differently by male and female viewers.</p>\n",
    "\n",
    "<p style='font-size:16px'> I can check this by conducting null hypothesis testing</p>\n",
    "<p style='font-size:16px'> Hypothesis: Given movie is rated differently by gender</p>\n",
    "<p style='font-size:16px'> Null hypothesis: Given movie is not rated differently by gender</p>\n",
    "<p style='font-size:16px'> I will assume that the null hypothesis is true</p><br>\n",
    "\n",
    "<p style='font-size:16px'>  I divided viewers into male and female. Then for each movies, I've conducted Mann-Whitney U test and caclulated p-value. I am using  Mann-Whitney U test test since I am comparing 2 groups that are nonparametric, and movie ratings data is ordinal data.</p><br>\n",
    "\n",
    "<p style='font-size:16px'> By classifying p-value based on significant level a=0.005, I got 50 movies with relatively small p-values, and 350 movies with relatively big p-values.</p>\n",
    "\n",
    "<p style='font-size:16px'> Therefore, proportion of movies rated differently by gender is 0.125</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e82a7f0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter by male and female viewers \n",
    "dataset_male = dataset[dataset.iloc[:, 474] == 1.0].iloc[:, :400]\n",
    "dataset_female = dataset[dataset.iloc[:, 474] == 2.0].iloc[:, :400]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "7e39d227",
   "metadata": {},
   "outputs": [],
   "source": [
    "# small: reject null hypothesis, so effective\n",
    "# big: don't reject null hypothesis, so not effective \n",
    "# len(dataset_male.columns) == len(dataset_female.columns) == 400\n",
    "\n",
    "# iterate by each movies and calculate p-value\n",
    "# for each male and female ratings, drop null values element-wise and compare \n",
    "# if p-value is relatively small(p < 0.005), add count to small\n",
    "# if p-value is relatively big(p >= 0.005), add count to big\n",
    "\n",
    "small = 0\n",
    "big = 0\n",
    "\n",
    "for i in range(len(dataset_male.columns)):\n",
    "    male_rating = dataset_male.iloc[:,i]\n",
    "    male_rating = male_rating[pd.notnull(male_rating)]\n",
    "    \n",
    "    female_rating = dataset_female.iloc[:,i]\n",
    "    female_rating = female_rating[pd.notnull(female_rating)]\n",
    "    \n",
    "    u1, p1 = stats.mannwhitneyu(male_rating, female_rating)\n",
    "    \n",
    "    if p1 < 0.005:\n",
    "        small += 1\n",
    "    else:\n",
    "        big += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f9186e7e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "small p-values: 50, big p-values: 350, proportion:0.125\n"
     ]
    }
   ],
   "source": [
    "# Calculate proportion\n",
    "proportion = small / (small+big)\n",
    "print('small p-values: {0}, big p-values: {1}, proportion:{2}'.format(small, big, proportion))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b93e4548",
   "metadata": {},
   "source": [
    "<p style='font-weight:bold; font-size:18px'>5) Do people who are only children enjoy ‘The Lion King (1994)’ more than people with siblings?</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53766eb5",
   "metadata": {},
   "source": [
    "<p style='font-weight:bold; font-size:18px'> Answer) </p>\n",
    "\n",
    "<p style='font-size:16px'> I've assumed that if rating is high, people enjoyed the movie.</p>\n",
    "<p style='font-size:16px'> Now, I can check this by conducting null hypothesis testing</p>\n",
    "<p style='font-size:16px'> Hypothesis: The Lion King (1994) was enjoyed(rated) more to people with only chidren than people with siblings.</p>\n",
    "<p style='font-size:16px'> Null hypothesis: The Lion King (1994) was not enjoyed(rated) more to people with only chidren than people with siblings</p><br>\n",
    "<p style='font-size:16px'> I will assume that the null hypothesis is true</p><br>\n",
    "\n",
    "<p style='font-size:16px'>  I divided The Lion King (1994) movie by people with only child and people with siblings. Then I've conducted Mann-Whitney U test and caclulated p-value. I am using  Mann-Whitney U test test since I am comparing 2 groups that are nonparametric, and movie ratings data is ordinal data.</p><br>\n",
    "\n",
    "<p style='font-size:16px'> p-value was relatively big(0.04319872995682849) compared to significant level a=0.005</p>\n",
    "\n",
    "\n",
    "<p style='font-size:16px'> So, we don't do anything because we already assumed that the null hypothesis is true. In english, The Lion King (1994) was not enjoyed(rated) more to people with only chidren than people with siblings.(below are detailed codes that follow my conclusion)</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "82a8e507",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       " 0    894\n",
       " 1    177\n",
       "-1     26\n",
       "Name: Are you an only child? (1: Yes; 0: No; -1: Did not respond), dtype: int64"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking child column. I've assumed 1 as people with only child, and 0 as people with siblings. \n",
    "# I didn't used -1 value, since we cannot decide no respond.\n",
    "dataset.iloc[:, 475].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "f1e4d894",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for each only_child and siblings ratings, drop null values element-wise and compare \n",
    "only_child = dataset[dataset.iloc[:, 475] == 1.0]['The Lion King (1994)']\n",
    "only_child = only_child[pd.notnull(only_child)]\n",
    "\n",
    "siblings = dataset[dataset.iloc[:, 475] == 0.0]['The Lion King (1994)']\n",
    "siblings = siblings[pd.notnull(siblings)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "df9223bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(52929.0, 0.04319872995682849)"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Then, calculate p-value by using Mann-Whitney U test\n",
    "# I am using U test since I am comparing 2 groups that are nonparametric, and movie ratings data is ordinal data.\n",
    "\n",
    "# p-value was relatively big(0.04319872995682849) compared to significant level a=0.005\n",
    "# So, we don't do anything because we already assumed that the null hypothesis is true\n",
    "# In english, The Lion King (1994) was not enjoyed(rated) more to people \n",
    "# who are only chidren than people with siblings.\n",
    "u1, p1 = stats.mannwhitneyu(only_child, siblings)\n",
    "u1, p1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93b8de97",
   "metadata": {},
   "source": [
    "<p style='font-weight:bold; font-size:18px'>6) What proportion of movies exhibit an “only child effect”, i.e. are rated different by viewers with siblings vs. those without?</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24deb479",
   "metadata": {},
   "source": [
    "<p style='font-weight:bold; font-size:18px'> Answer) </p>\n",
    "\n",
    "<p style='font-size:16px'> I will apply below null hypothesis testing to each movies and calculate proportion of movies that have relatively small p-value. If p-value is relatively small, I can conclude that given movie is rated differently by viewers with siblings vs. those without.</p>\n",
    "\n",
    "<p style='font-size:16px'> I can check this by conducting null hypothesis testing</p>\n",
    "<p style='font-size:16px'> Hypothesis: Given movie is rated differently by people with only chidren and people with siblings.</p>\n",
    "<p style='font-size:16px'> Null hypothesis: Given movie is not rated differently by people with only children and people with siblings.</p>\n",
    "<p style='font-size:16px'> I will assume that the null hypothesis is true</p><br>\n",
    "\n",
    "<p style='font-size:16px'>  I divided viewers into people with only children and people with siblings. Then for each movies, I've conducted Mann-Whitney U test and caclulated p-value. I am using  Mann-Whitney U test test since I am comparing 2 groups that are nonparametric, and movie ratings data is ordinal data.</p><br>\n",
    "\n",
    "<p style='font-size:16px'> By classifying p-value based on significant level a=0.005, I got 7 movies with relatively small p-values, and 393 movies with relatively big p-values.</p>\n",
    "\n",
    "<p style='font-size:16px'> Therefore, proportion of movies rated differently by 'only child effect' is 0.0175</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "b869a47b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter by onlychild and siblings\n",
    "dataset_onlychild = dataset[dataset.iloc[:, 475] == 1.0].iloc[:, :400]\n",
    "dataset_morechild = dataset[dataset.iloc[:, 475] == 0.0].iloc[:, :400]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "90305751",
   "metadata": {},
   "outputs": [],
   "source": [
    "# small: reject null hypothesis, so effective\n",
    "# big: don't reject null hypothesis, so not effective \n",
    "# len(dataset_onlychild.columns) == len(dataset_morechild.columns) == 400\n",
    "\n",
    "# iterate by each movies and calculate p-value\n",
    "# for each onlychild and siblings ratings, drop null values element-wise and compare \n",
    "# if p-value is relatively small(p < 0.005), add count to small\n",
    "# if p-value is relatively big(p >= 0.005), add count to big\n",
    "\n",
    "small = 0\n",
    "big = 0\n",
    "\n",
    "for i in range(len(dataset_onlychild.columns)):\n",
    "    onlychild = dataset_onlychild.iloc[:,i]\n",
    "    onlychild = onlychild[pd.notnull(onlychild)]\n",
    "    \n",
    "    morechild = dataset_morechild.iloc[:,i]\n",
    "    morechild = morechild[pd.notnull(morechild)]\n",
    "    \n",
    "    u1, p1 = stats.mannwhitneyu(onlychild, morechild)\n",
    "    \n",
    "    if p1 < 0.005:\n",
    "        small += 1\n",
    "    else:\n",
    "        big += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "63727a8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "small p-values: 7, big p-values: 393, proportion:0.0175\n"
     ]
    }
   ],
   "source": [
    "# Calculate proportion\n",
    "proportion = small / (small+big)\n",
    "print('small p-values: {0}, big p-values: {1}, proportion:{2}'.format(small, big, proportion))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acb5510a",
   "metadata": {},
   "source": [
    "<p style='font-weight:bold; font-size:18px'>7) Do people who like to watch movies socially enjoy ‘The Wolf of Wall Street (2013)’ more than those who prefer to watch them alone?</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b05e03b",
   "metadata": {},
   "source": [
    "<p style='font-weight:bold; font-size:18px'> Answer) </p>\n",
    "\n",
    "<p style='font-size:16px'> I've assumed that if rating is high, than peopled enjoyed the movie.</p>\n",
    "<p style='font-size:16px'> Now, I can check this by conducting null hypothesis testing</p>\n",
    "<p style='font-size:16px'> Hypothesis: The Wolf of Wall Street (2013) was enjoyed(rated) more to people who like to watch movies socially than people who prefer to watch them alone.</p>\n",
    "<p style='font-size:16px'> Null hypothesis: The Wolf of Wall Street (2013) was not enjoyed(rated) more to people who like to watch movies socially than people who prefer to watch them alone.</p>\n",
    "<p style='font-size:16px'> I will assume that the null hypothesis is true</p><br>\n",
    "\n",
    "<p style='font-size:16px'>  I divided The Wolf of Wall Street (2013) movie by people who like to watch movies socially and people who prefer to watch them alone. Then I've conducted Mann-Whitney U test and caclulated p-value. I am using  Mann-Whitney U test test since I am comparing 2 groups that are nonparametric, and movie ratings data is ordinal data.</p><br>\n",
    "\n",
    "<p style='font-size:16px'> p-value was relatively big(0.1127642933222891) compared to significant level a=0.005</p>\n",
    "\n",
    "\n",
    "<p style='font-size:16px'> So, we don't do anything because we already assumed that the null hypothesis is true. In english, The Wolf of Wall Street (2013) was not enjoyed(rated) more to people who like to watch movies socially than people who prefer to watch them alone.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "8f71b038",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       " 1    610\n",
       " 0    462\n",
       "-1     25\n",
       "Name: Movies are best enjoyed alone (1: Yes; 0: No; -1: Did not respond), dtype: int64"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking movies enjoyed column. I've used 1 as people who like to watch movies socially, \n",
    "# and 0 as people who prefer to watch them alone. \n",
    "# I didn't used -1 value, since we cannot decide no respond.\n",
    "dataset.iloc[:, 476].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "5f220cb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for each movie by watching alone and watching socially, drop null values element-wise and compare \n",
    "movie_alone = dataset[dataset.iloc[:, 476] == 1.0]['The Wolf of Wall Street (2013)']\n",
    "movie_alone = movie_alone[pd.notnull(movie_alone)]\n",
    "\n",
    "movie_social = dataset[dataset.iloc[:, 476] == 0.0]['The Wolf of Wall Street (2013)']\n",
    "movie_social = movie_social[pd.notnull(movie_social)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "b100c644",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(56806.5, 0.1127642933222891)"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# p-value was relatively big(0.1127642933222891) compared to significant level a=0.005\n",
    "# So, we don't do anything because we already assumed that the null hypothesis is true\n",
    "# In english, The Wolf of Wall Street (2013) was not enjoyed(rated) more to people\n",
    "# who like to watch movies socially than people who prefer to watch them alone.\n",
    "\n",
    "u1, p1 = stats.mannwhitneyu(movie_alone, movie_social)\n",
    "u1, p1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d3a9213",
   "metadata": {},
   "source": [
    "<p style='font-weight:bold; font-size:18px'>8) What proportion of movies exhibit such a “social watching” effect?</p> "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ab057a9",
   "metadata": {},
   "source": [
    "<p style='font-weight:bold; font-size:18px'> Answer) </p>\n",
    "\n",
    "<p style='font-size:16px'> I will apply below null hypothesis testing to each movies and calculate proportion of movies that have relatively small p-value. If p-value is relatively small, I can conclude that given movie is rated differently by viewers with movies watching alone and watching socially.</p>\n",
    "\n",
    "<p style='font-size:16px'> I can check this by conducting null hypothesis testing</p>\n",
    "<p style='font-size:16px'> Hypothesis: Given movie is rated differently by people watching movies alone or watching socially.</p>\n",
    "<p style='font-size:16px'> Null hypothesis: Given movie is not rated differently by people watching movies alone or watching socially</p><br>\n",
    "<p style='font-size:16px'> I will assume that the null hypothesis is true</p><br>\n",
    "\n",
    "<p style='font-size:16px'>  I divided viewers into people watching movies alone or watching socially. Then for each movies, I've conducted Mann-Whitney U test and caclulated p-value. I am using  Mann-Whitney U test test since I am comparing 2 groups that are nonparametric, and movie ratings data is ordinal data.</p><br>\n",
    "\n",
    "<p style='font-size:16px'> By classifying p-value based on significant level a=0.005, I got 10 movies with relatively small p-values, and 390 movies with relatively big p-values.</p>\n",
    "\n",
    "<p style='font-size:16px'> Therefore, proportion of movies rated differently by 'social watching effect' is 0.025</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "bb227ca0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter by people watching movies alone or watching socially\n",
    "movies_alone = dataset[dataset.iloc[:, 476] == 0.0].iloc[:, :400]\n",
    "movies_social = dataset[dataset.iloc[:, 476] == 1.0].iloc[:, :400]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "24e7e75f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# small: reject null hypothesis, so effective\n",
    "# big: don't reject null hypothesis, so not effective \n",
    "# len(movies_alone.columns) == len(movies_social.columns) == 400\n",
    "\n",
    "# iterate by each movies and calculate p-value\n",
    "# for each movies_alone and movies_social ratings, drop null values element-wise and compare \n",
    "# if p-value is relatively small(p < 0.005), add count to small\n",
    "# if p-value is relatively big(p >= 0.005), add count to big\n",
    "\n",
    "small = 0\n",
    "big = 0\n",
    "\n",
    "for i in range(len(movies_alone.columns)):\n",
    "    alone = movies_alone.iloc[:,i]\n",
    "    alone = alone[pd.notnull(alone)]\n",
    "    \n",
    "    social = movies_social.iloc[:,i]\n",
    "    social = social[pd.notnull(social)]\n",
    "    \n",
    "    u1, p1 = stats.mannwhitneyu(alone, social)\n",
    "    \n",
    "    if p1 < 0.005:\n",
    "        small += 1\n",
    "    else:\n",
    "        big += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "f901af25",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "small p-values: 10, big p-values: 390, proportion:0.025\n"
     ]
    }
   ],
   "source": [
    "# Calculate proportion\n",
    "proportion = small / (small+big)\n",
    "print('small p-values: {0}, big p-values: {1}, proportion:{2}'.format(small, big, proportion))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6556352",
   "metadata": {},
   "source": [
    "<p style='font-weight:bold; font-size:18px'>9) Is the ratings distribution of ‘Home Alone (1990)’ different than that of ‘Finding Nemo (2003)’?</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "343bef4f",
   "metadata": {},
   "source": [
    "<p style='font-weight:bold; font-size:18px'> Answer) </p>\n",
    "\n",
    "<p style='font-size:16px'> I can check this by conducting null hypothesis testing</p>\n",
    "<p style='font-size:16px'> Hypothesis: Ratings distribution of ‘Home Alone (1990)’ is different than that of ‘Finding Nemo (2003)'.</p>\n",
    "<p style='font-size:16px'> Null hypothesis: Ratings distribution of ‘Home Alone (1990)’ is not different than that of ‘Finding Nemo (2003)'.</p><br>\n",
    "<p style='font-size:16px'> I will assume that the null hypothesis is true</p><br>\n",
    "\n",
    "<p style='font-size:16px'>  I created datasets of movie rating ‘Home Alone (1990)’ and ‘Finding Nemo (2003)'. Then I've dropped null values element-wise.</p>\n",
    "<p style='font-size:16px'> Then I've conducted Kolmogorov-Smirnov(KS) test and caclulated p-value. I am using Kolmogorov-Smirnov(KS) test since I am comparing shapes of distribution of 2 groups that are nonparametric, and movie ratings data is ordinal data.</p><br>\n",
    "\n",
    "<p style='font-size:16px'> p-value was relatively small(6.379381467525036e-10) compared to significant level a=0.005</p>\n",
    "\n",
    "<p style='font-size:16px'> So, I rejected the null hypothesis. In english, I've concluded that ratings distribution of ‘Home Alone (1990)’ is different than that of ‘Finding Nemo (2003)'.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "5fe565d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "dist_home_alone = dataset['Home Alone (1990)']\n",
    "dist_home_alone = dist_home_alone[pd.notnull(dist_home_alone)]\n",
    "\n",
    "dist_find_nemo = dataset['Finding Nemo (2003)']\n",
    "dist_find_nemo = dist_find_nemo[pd.notnull(dist_find_nemo)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "4a2126ed",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.15269080020897632, 6.379381467525036e-10)"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# p-value was relatively small(6.379381467525036e-10)) compared to significant level a=0.005\n",
    "# reject null hypothesis and conclude that Ratings distribution of ‘Home Alone (1990)’ \n",
    "# is different than that of ‘Finding Nemo (2003)'.\n",
    "u1, p1 = stats.kstest(dist_home_alone, dist_find_nemo)\n",
    "u1, p1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fe73e0a",
   "metadata": {},
   "source": [
    "<p style='font-weight:bold; font-size:18px'>10) There are ratings on movies from several franchises ([‘Star Wars’, ‘Harry Potter’, ‘The Matrix’, ‘Indiana Jones’, ‘Jurassic Park’, ‘Pirates of the Caribbean’, ‘Toy Story’, ‘Batman’]) in this dataset. How many of these are of inconsistent quality, as experienced by viewers? [Hint: You can use the keywords in quotation marks featured in this question to identify the movies that are part of each franchise]</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7725c6ad",
   "metadata": {},
   "source": [
    "<p style='font-weight:bold; font-size:18px'> Answer) </p>\n",
    "\n",
    "<p style='font-size:16px'> For each franchises, I will check its inconsistent quality by comparing ratings of every pairs in each franchise series.(i.e. compare every pairs in star wars series). If one of the comparision result appears to have relatively small p-value(therefore null-hypothesis was rejected), then given franchise has inconsistent quality. </p>\n",
    "<p style='font-size:16px'> Also, I will assume that if ratings are different, it means inconsistent quality. </p>\n",
    "\n",
    "<p style='font-size:16px'> Now, I can check inconsistency by conducting null hypothesis testing</p>\n",
    "<p style='font-size:16px'> Hypothesis: Given pair of movies has inconsistent quality.(rated differently)</p>\n",
    "<p style='font-size:16px'> Null hypothesis: Given pair of movies doesn't have inconsistent quality.(not rated differently)'.</p><br>\n",
    "<p style='font-size:16px'> I will assume that the null hypothesis is true</p><br>\n",
    "\n",
    "\n",
    "<p style='font-size:16px'>  I've filtered movies by each franchise series. Then for each franchise series, I've conducted Mann-Whitney U test and caclulated p-value for every pairs of franchise series. I am using  Mann-Whitney U test test since I am comparing 2 groups that are nonparametric, and movie ratings data is ordinal data.</p>\n",
    "<p style='font-size:16px'> By classifying p-value based on significant level a=0.005, I've got below results for each franchise series.</p><br>\n",
    "\n",
    "<p style='font-weight:bold;font-size:16px'> - Starwars series have inconsistent quality </p>\n",
    "<p style='font-size:16px'> We have total 6 series, so conducted 15 comparison. Result: 8 rejects and 7 accepts. Therefore, Matrix series have inconsistent quality </p><br>\n",
    "\n",
    "<p style='font-weight:bold;font-size:16px'> - Harry Potter series have consistent quality </p>\n",
    "<p style='font-size:16px'> We have total 4 series, so conducted 6 comparison. Result: 0 rejects and 6 accepts. Therefore, Harry Potter series have consistent quality</p><br>\n",
    "\n",
    "\n",
    "<p style='font-weight:bold;font-size:16px'> - Matrix series have inconsistent quality </p>\n",
    "<p style='font-size:16px'> We have total 3 series, so conducted 3 comparisons. Result: 2 rejects and 1 accepts. Therefore, Matrix series have inconsistent quality</p><br>\n",
    "\n",
    "<p style='font-weight:bold;font-size:16px'> - Indiana Jones series have inconsistent quality </p>\n",
    "<p style='font-size:16px'> We have total 4 series, so conducted 6 comparisons. Result: 4 rejects and 2 accepts Therefore, Indiana Jones series have inconsistent quality</p><br>\n",
    "\n",
    "<p style='font-weight:bold;font-size:16px'> - Jurassic Park series have inconsistent quality </p>\n",
    "<p style='font-size:16px'> We have total 3 series, so conducted 3 comparisons. Result: 3 rejects and 0 accepts\n",
    "Therefore, Jurassic Park series have inconsistent quality.</p><br>\n",
    "\n",
    "<p style='font-weight:bold;font-size:16px'> - Pirates of the Caribbean series have inconsistent quality </p>\n",
    "<p style='font-size:16px'> We have total 3 series, so conducted 3 comparisons. Result: 2 rejects and 1 accepts\n",
    "Therefore, Pirates of the Caribbean series have inconsistent quality</p><br>\n",
    "\n",
    "<p style='font-weight:bold;font-size:16px'> - Toy Story series have inconsistent quality </p>\n",
    "<p style='font-size:16px'> We have total 3 series, so conducted 3 comparisons.Result: 2 rejects and 1 accepts\n",
    "Therefore, Toy Story series have inconsistent quality</p><br>\n",
    "\n",
    "<p style='font-weight:bold;font-size:16px'> - Batman series have inconsistent quality </p>\n",
    "<p style='font-size:16px'> We have total 3 series, so conducted 3 comparisons. Result: 3 rejects and 0 accepts\n",
    "Therefore, Batman series have inconsistent quality</p><br>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "d46c60fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filtering movies by franchise name  \n",
    "starwars, harry, matrix, indiana, jurassic, pirate, toy, batman = [], [], [], [], [], [], [], []\n",
    "movies = dataset.columns[:400]\n",
    "\n",
    "for movie in movies:\n",
    "    if 'Star Wars' in movie:\n",
    "        starwars.append(movie)\n",
    "    elif 'Harry Potter' in movie:\n",
    "        harry.append(movie)\n",
    "    elif 'The Matrix' in movie:\n",
    "        matrix.append(movie)\n",
    "    elif 'Indiana Jones' in movie:\n",
    "        indiana.append(movie)\n",
    "    elif 'Jurassic Park' in movie:\n",
    "        jurassic.append(movie)\n",
    "    elif 'Pirates of the Caribbean' in movie:\n",
    "        pirate.append(movie)\n",
    "    elif 'Toy Story' in movie:\n",
    "        toy.append(movie)\n",
    "    elif 'Batman' in movie:\n",
    "        batman.append(movie)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "4a6cb6e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For each series, create a new array that contains each series rating data\n",
    "starwars_test = []\n",
    "\n",
    "for i in starwars:\n",
    "    movie = dataset[i]\n",
    "    movie = np.array(movie[pd.notnull(movie)])\n",
    "    starwars_test.append(movie)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "58a8956e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reject null) Series between case 1 and case 2 p-value: 0.000000\n",
      "Accept null) Series between case 1 and case 3 p-value: 0.081898\n",
      "Reject null) Series between case 1 and case 4 p-value: 0.000000\n",
      "Accept null) Series between case 1 and case 5 p-value: 0.023967\n",
      "Accept null) Series between case 1 and case 6 p-value: 0.494681\n",
      "Reject null) Series between case 2 and case 3 p-value: 0.000000\n",
      "Accept null) Series between case 2 and case 4 p-value: 0.450309\n",
      "Reject null) Series between case 2 and case 5 p-value: 0.000000\n",
      "Reject null) Series between case 2 and case 6 p-value: 0.000000\n",
      "Reject null) Series between case 3 and case 4 p-value: 0.000000\n",
      "Accept null) Series between case 3 and case 5 p-value: 0.573254\n",
      "Accept null) Series between case 3 and case 6 p-value: 0.303426\n",
      "Reject null) Series between case 4 and case 5 p-value: 0.000000\n",
      "Reject null) Series between case 4 and case 6 p-value: 0.000000\n",
      "Accept null) Series between case 5 and case 6 p-value: 0.114050\n",
      "\n",
      "We have total 6 series, so conducted 15 comparisons.\n",
      "Result: 8 rejects and 7 accepts\n",
      "Therefore, Star Wars series have inconsistent quality.\n"
     ]
    }
   ],
   "source": [
    "# Compare every pair of movies in series\n",
    "reject, accept = 0, 0\n",
    "for i in range(len(starwars_test)):\n",
    "    for j in range(i+1, len(starwars_test)):\n",
    "        u, p = stats.mannwhitneyu(starwars_test[i], starwars_test[j])\n",
    "        if p < 0.005:\n",
    "            print('Reject null) Series between case {0} and case {1} p-value: {2:.6f}'.format(i+1, j+1, p))\n",
    "            reject += 1\n",
    "        else:\n",
    "            print('Accept null) Series between case {0} and case {1} p-value: {2:.6f}'.format(i+1, j+1, p))\n",
    "            accept += 1\n",
    "print()\n",
    "print('We have total {0} series, so conducted {1} comparisons.\\nResult: {2} rejects and {3} accepts'\n",
    "      .format(len(starwars_test), reject+accept, reject, accept))\n",
    "print('Therefore, Star Wars series have inconsistent quality.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "a1d51b05",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For each series, create a new array that contains each series rating data\n",
    "harry_test = []\n",
    "\n",
    "for i in harry:\n",
    "    movie = dataset[i]\n",
    "    movie = np.array(movie[pd.notnull(movie)])\n",
    "    harry_test.append(movie)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "49c8aaa4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accept null) Series between case 1 and case 2 p-value: 0.461328\n",
      "Accept null) Series between case 1 and case 3 p-value: 0.158534\n",
      "Accept null) Series between case 1 and case 4 p-value: 0.098167\n",
      "Accept null) Series between case 2 and case 3 p-value: 0.497306\n",
      "Accept null) Series between case 2 and case 4 p-value: 0.361903\n",
      "Accept null) Series between case 3 and case 4 p-value: 0.804052\n",
      "\n",
      "We have total 4 series, so conducted 6 comparisons.\n",
      "Result: 0 rejects and 6 accepts\n",
      "Therefore, Harry Potter series have consistent quality.\n"
     ]
    }
   ],
   "source": [
    "# Compare every pair of movies in series\n",
    "reject, accept = 0, 0\n",
    "for i in range(len(harry_test)):\n",
    "    for j in range(i+1, len(harry_test)):\n",
    "        u, p = stats.mannwhitneyu(harry_test[i], harry_test[j])\n",
    "        if p < 0.005:\n",
    "            print('Reject null) Series between case {0} and case {1} p-value: {2:.6f}'.format(i+1, j+1, p))\n",
    "            reject += 1\n",
    "        else:\n",
    "            print('Accept null) Series between case {0} and case {1} p-value: {2:.6f}'.format(i+1, j+1, p))\n",
    "            accept += 1\n",
    "print()\n",
    "print('We have total {0} series, so conducted {1} comparisons.\\nResult: {2} rejects and {3} accepts'\n",
    "      .format(len(harry_test), reject+accept, reject, accept))\n",
    "print('Therefore, Harry Potter series have consistent quality.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "62c3d149",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For each series, create a new array that contains each series rating data\n",
    "matrix_test = []\n",
    "\n",
    "for i in matrix:\n",
    "    movie = dataset[i]\n",
    "    movie = np.array(movie[pd.notnull(movie)])\n",
    "    matrix_test.append(movie)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "eb7f4095",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accept null) Series between case 1 and case 2 p-value: 0.249811\n",
      "Reject null) Series between case 1 and case 3 p-value: 0.000000\n",
      "Reject null) Series between case 2 and case 3 p-value: 0.000000\n",
      "\n",
      "We have total 3 series, so conducted 3 comparisons.\n",
      "Result: 2 rejects and 1 accepts\n",
      "Therefore, Matrix series have inconsistent quality.\n"
     ]
    }
   ],
   "source": [
    "# Compare every pair of movies in series\n",
    "reject, accept = 0, 0\n",
    "for i in range(len(matrix_test)):\n",
    "    for j in range(i+1, len(matrix_test)):\n",
    "        u, p = stats.mannwhitneyu(matrix_test[i], matrix_test[j])\n",
    "        if p < 0.005:\n",
    "            print('Reject null) Series between case {0} and case {1} p-value: {2:.6f}'.format(i+1, j+1, p))\n",
    "            reject += 1\n",
    "        else:\n",
    "            print('Accept null) Series between case {0} and case {1} p-value: {2:.6f}'.format(i+1, j+1, p))\n",
    "            accept += 1\n",
    "print()\n",
    "print('We have total {0} series, so conducted {1} comparisons.\\nResult: {2} rejects and {3} accepts'\n",
    "      .format(len(matrix_test), reject+accept, reject, accept))\n",
    "print('Therefore, Matrix series have inconsistent quality.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "9dbef24d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For each series, create a new array that contains each series rating data\n",
    "indiana_test = []\n",
    "\n",
    "for i in indiana:\n",
    "    movie = dataset[i]\n",
    "    movie = np.array(movie[pd.notnull(movie)])\n",
    "    indiana_test.append(movie)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "bb3408fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accept null) Series between case 1 and case 2 p-value: 0.307084\n",
      "Reject null) Series between case 1 and case 3 p-value: 0.000603\n",
      "Reject null) Series between case 1 and case 4 p-value: 0.000178\n",
      "Reject null) Series between case 2 and case 3 p-value: 0.000018\n",
      "Accept null) Series between case 2 and case 4 p-value: 0.005199\n",
      "Reject null) Series between case 3 and case 4 p-value: 0.000000\n",
      "\n",
      "We have total 4 series, so conducted 6 comparisons.\n",
      "Result: 4 rejects and 2 accepts\n",
      "Therefore, Indiana Jones series have inconsistent quality.\n"
     ]
    }
   ],
   "source": [
    "# Compare every pair of movies in series\n",
    "reject, accept = 0, 0\n",
    "for i in range(len(indiana_test)):\n",
    "    for j in range(i+1, len(indiana_test)):\n",
    "        u, p = stats.mannwhitneyu(indiana_test[i], indiana_test[j])\n",
    "        if p < 0.005:\n",
    "            print('Reject null) Series between case {0} and case {1} p-value: {2:.6f}'.format(i+1, j+1, p))\n",
    "            reject += 1\n",
    "        else:\n",
    "            print('Accept null) Series between case {0} and case {1} p-value: {2:.6f}'.format(i+1, j+1, p))\n",
    "            accept += 1\n",
    "print()\n",
    "print('We have total {0} series, so conducted {1} comparisons.\\nResult: {2} rejects and {3} accepts'\n",
    "      .format(len(indiana_test), reject+accept, reject, accept))\n",
    "print('Therefore, Indiana Jones series have inconsistent quality.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "8f68c18a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For each series, create a new array that contains each series rating data\n",
    "jurassic_test = []\n",
    "\n",
    "for i in jurassic:\n",
    "    movie = dataset[i]\n",
    "    movie = np.array(movie[pd.notnull(movie)])\n",
    "    jurassic_test.append(movie)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "ec279d18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reject null) Series between case 1 and case 2 p-value: 0.000275\n",
      "Reject null) Series between case 1 and case 3 p-value: 0.000674\n",
      "Reject null) Series between case 2 and case 3 p-value: 0.000000\n",
      "\n",
      "We have total 3 series, so conducted 3 comparisons.\n",
      "Result: 3 rejects and 0 accepts\n",
      "Therefore, Jurassic Park series have inconsistent quality.\n"
     ]
    }
   ],
   "source": [
    "# Compare every pair of movies in series\n",
    "reject, accept = 0, 0\n",
    "for i in range(len(jurassic_test)):\n",
    "    for j in range(i+1, len(jurassic_test)):\n",
    "        u, p = stats.mannwhitneyu(jurassic_test[i], jurassic_test[j])\n",
    "        if p < 0.005:\n",
    "            print('Reject null) Series between case {0} and case {1} p-value: {2:.6f}'.format(i+1, j+1, p))\n",
    "            reject += 1\n",
    "        else:\n",
    "            print('Accept null) Series between case {0} and case {1} p-value: {2:.6f}'.format(i+1, j+1, p))\n",
    "            accept += 1\n",
    "print()\n",
    "print('We have total {0} series, so conducted {1} comparisons.\\nResult: {2} rejects and {3} accepts'\n",
    "      .format(len(jurassic_test), reject+accept, reject, accept))\n",
    "print('Therefore, Jurassic Park series have inconsistent quality.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "37154338",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For each series, create a new array that contains each series rating data\n",
    "pirate_test = []\n",
    "\n",
    "for i in pirate:\n",
    "    movie = dataset[i]\n",
    "    movie = np.array(movie[pd.notnull(movie)])\n",
    "    pirate_test.append(movie)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "48b86066",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accept null) Series between case 1 and case 2 p-value: 0.251478\n",
      "Reject null) Series between case 1 and case 3 p-value: 0.000009\n",
      "Reject null) Series between case 2 and case 3 p-value: 0.001758\n",
      "\n",
      "We have total 3 series, so conducted 3 comparisons.\n",
      "Result: 2 rejects and 1 accepts\n",
      "Therefore, Pirates of the Caribbean series have inconsistent quality.\n"
     ]
    }
   ],
   "source": [
    "# Compare every pair of movies in series\n",
    "reject, accept = 0, 0\n",
    "for i in range(len(pirate_test)):\n",
    "    for j in range(i+1, len(pirate_test)):\n",
    "        u, p = stats.mannwhitneyu(pirate_test[i], pirate_test[j])\n",
    "        if p < 0.005:\n",
    "            print('Reject null) Series between case {0} and case {1} p-value: {2:.6f}'.format(i+1, j+1, p))\n",
    "            reject += 1\n",
    "        else:\n",
    "            print('Accept null) Series between case {0} and case {1} p-value: {2:.6f}'.format(i+1, j+1, p))\n",
    "            accept += 1\n",
    "print()\n",
    "print('We have total {0} series, so conducted {1} comparisons.\\nResult: {2} rejects and {3} accepts'\n",
    "      .format(len(pirate_test), reject+accept, reject, accept))\n",
    "print('Therefore, Pirates of the Caribbean series have inconsistent quality.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "bb6a0d89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For each series, create a new array that contains each series rating data\n",
    "toy_test = []\n",
    "\n",
    "for i in toy:\n",
    "    movie = dataset[i]\n",
    "    movie = np.array(movie[pd.notnull(movie)])\n",
    "    toy_test.append(movie)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "7f5ec037",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reject null) Series between case 1 and case 2 p-value: 0.000084\n",
      "Reject null) Series between case 1 and case 3 p-value: 0.000006\n",
      "Accept null) Series between case 2 and case 3 p-value: 0.539633\n",
      "\n",
      "We have total 3 series, so conducted 3 comparisons.\n",
      "Result: 2 rejects and 1 accepts\n",
      "Therefore, Toy Story series have inconsistent quality.\n"
     ]
    }
   ],
   "source": [
    "# Compare every pair of movies in series\n",
    "reject, accept = 0, 0\n",
    "for i in range(len(toy_test)):\n",
    "    for j in range(i+1, len(toy_test)):\n",
    "        u, p = stats.mannwhitneyu(toy_test[i], toy_test[j])\n",
    "        if p < 0.005:\n",
    "            print('Reject null) Series between case {0} and case {1} p-value: {2:.6f}'.format(i+1, j+1, p))\n",
    "            reject += 1\n",
    "        else:\n",
    "            print('Accept null) Series between case {0} and case {1} p-value: {2:.6f}'.format(i+1, j+1, p))\n",
    "            accept += 1\n",
    "print()\n",
    "print('We have total {0} series, so conducted {1} comparisons.\\nResult: {2} rejects and {3} accepts'\n",
    "      .format(len(toy_test), reject+accept, reject, accept))\n",
    "print('Therefore, Toy Story series have inconsistent quality.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "55667284",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For each series, create a new array that contains each series rating data\n",
    "batman_test = []\n",
    "\n",
    "for i in batman:\n",
    "    movie = dataset[i]\n",
    "    movie = np.array(movie[pd.notnull(movie)])\n",
    "    batman_test.append(movie)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "257bc44d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reject null) Series between case 1 and case 2 p-value: 0.000000\n",
      "Reject null) Series between case 1 and case 3 p-value: 0.000000\n",
      "Reject null) Series between case 2 and case 3 p-value: 0.000000\n",
      "\n",
      "We have total 3 series, so conducted 3 comparisons.\n",
      "Result: 3 rejects and 0 accepts\n",
      "Therefore, Batman series have inconsistent quality.\n"
     ]
    }
   ],
   "source": [
    "# Compare every pair of movies in series\n",
    "reject, accept = 0, 0\n",
    "for i in range(len(batman_test)):\n",
    "    for j in range(i+1, len(batman_test)):\n",
    "        u, p = stats.mannwhitneyu(batman_test[i], batman_test[j])\n",
    "        if p < 0.005:\n",
    "            print('Reject null) Series between case {0} and case {1} p-value: {2:.6f}'.format(i+1, j+1, p))\n",
    "            reject += 1\n",
    "        else:\n",
    "            print('Accept null) Series between case {0} and case {1} p-value: {2:.6f}'.format(i+1, j+1, p))\n",
    "            accept += 1\n",
    "print()\n",
    "print('We have total {0} series, so conducted {1} comparisons.\\nResult: {2} rejects and {3} accepts'\n",
    "      .format(len(batman_test), reject+accept, reject, accept))\n",
    "print('Therefore, Batman series have inconsistent quality.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6290e9a",
   "metadata": {},
   "source": [
    "<p style='font-weight:bold; font-size:18px'>Extra Credit: Tell us something interesting and true (supported by a significance test of some kind) about the movies in this dataset that is not already covered by the questions above [for 5% of the grade score].</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f5c7741",
   "metadata": {},
   "source": [
    "<p style='font-weight:bold; font-size:18px'> Extra - (1) </p>\n",
    "<p style='font-size:16px'> 'Scream (1996)' was rated more to people who enjoys watching horror movies than those who don't enjoy watching horror movies. So, people's tendency of enjoying horror movies actually affect rating of horror movie 'Scream (1996)'. (It can be true even before testing, but is interesting to see the actual result!) </p>\n",
    "\n",
    "<p style='font-weight:bold; font-size:18px'> Explanation) </p>\n",
    "<p style='font-size:16px'> I can check this by conducting null hypothesis testing</p>\n",
    "<p style='font-size:16px'> Hypothesis: 'Scream (1996)' was rated more to people who enjoys watching horror movies than those who don't enjoy watching horror movies. </p>\n",
    "<p style='font-size:16px'> Null hypothesis: 'Scream (1996)' was not rated more to people who enjoys watching horror movies than those who don't enjoy watching horror movies. </p><br>\n",
    "<p style='font-size:16px'> I will assume that the null hypothesis is true</p><br>\n",
    "\n",
    "<p style='font-size:16px'>  I divided 'Scream (1996)' movie into people who enjoys watching horror movies and people who don't enjoy watching horror movies. Then I've conducted Mann-Whitney U test and caclulated p-value. I am using  Mann-Whitney U test test since I am comparing 2 groups that are nonparametric, and movie ratings data is ordinal data.</p><br>\n",
    "\n",
    "<p style='font-size:16px'> p-value was relatively small(4.5909393543455896e-08) compared to significant level a=0.005</p>\n",
    "\n",
    "<p style='font-size:16px'> So, I rejected the null hypothesis. In english, 'Scream (1996)' was rated more to people who enjoys watching horror movies than those who don't enjoy watching horror movies.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "f03ab288",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0    316\n",
       "5.0    269\n",
       "4.0    253\n",
       "2.0    140\n",
       "3.0    114\n",
       "Name: I enjoy watching horror movies, dtype: int64"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking distribution of column 'enjoy watching horror movies'\n",
    "dataset.iloc[:, 409].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "c073c361",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split 'Scream (1996)' into people enjoy watching horror movies and don't enjoy watching horror movies\n",
    "# I will divide into two groups by median rate(3.0) and won't be using 3.0 as it is a median rate\n",
    "# drop null values element-wise and compare \n",
    "\n",
    "horror_enjoy = dataset[dataset.iloc[:, 409] > 3.0]['Scream (1996)']\n",
    "horror_enjoy = horror_enjoy[pd.notnull(horror_enjoy)]\n",
    "\n",
    "horror_dont_enjoy = dataset[dataset.iloc[:, 409] < 3.0]['Scream (1996)']\n",
    "horror_dont_enjoy = horror_dont_enjoy[pd.notnull(horror_dont_enjoy)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "d2bdc48c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(13535.5, 4.5909393543455896e-08)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# p-value was relatively small(4.5909393543455896e-08) compared to significant level a=0.005\n",
    "# So, I rejected the null hypothesis. In english, 'Scream (1996)' was rated more to people \n",
    "# who enjoys watching horror movies than those who don't enjoy watching horror movies.\n",
    "\n",
    "u1, p1 = stats.mannwhitneyu(horror_enjoy, horror_dont_enjoy)\n",
    "u1, p1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36be6f44",
   "metadata": {},
   "source": [
    "<p style='font-weight:bold; font-size:18px'> Extra - (2) </p>\n",
    "<p style='font-size:16px'> Let's assume that people who cries often during a movie tends to rate differently than people who don't often cry during a movie. </p>\n",
    "<p style='font-size:16px'> If we call this \"crying effect\", proportion of movies rated differently by '\"crying effect\" is 0.0425 </p>\n",
    "\n",
    "<p style='font-weight:bold; font-size:18px'> Explanation) </p>\n",
    "<p style='font-size:16px'> I will apply below null hypothesis testing to each movies and calculate proportion of movies that have relatively small p-value. If p-value is relatively small, I can conclude that given movie is rated differently by viewers with movies watching alone and watching socially.</p>\n",
    "\n",
    "<p style='font-size:16px'> Hypothesis: Given movie is rated differently by people crying or not crying(during the movie).</p>\n",
    "<p style='font-size:16px'> Null hypothesis: Given movie is not rated differently by people crying or not crying(during the movie).</p>\n",
    "<p style='font-size:16px'> I will assume that the null hypothesis is true</p><br>\n",
    "\n",
    "<p style='font-size:16px'>  I divided viewers into people cried during a movie and people didn't cry during a movie. Then for each movies, I've conducted Mann-Whitney U test and caclulated p-value. I am using  Mann-Whitney U test test since I am comparing 2 groups that are nonparametric, and movie ratings data is ordinal data.</p><br>\n",
    "\n",
    "<p style='font-size:16px'> By classifying p-value based on significant level a=0.005, I got 17 movies with relatively small p-values, and 383 movies with relatively big p-values.</p>\n",
    "\n",
    "<p style='font-size:16px'> Therefore, proportion of movies rated differently by \"crying effect\" is 0.0425</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "235d2a87",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.0    343\n",
       "5.0    273\n",
       "3.0    219\n",
       "6.0     98\n",
       "2.0     92\n",
       "1.0     55\n",
       "Name: I have cried during a movie, dtype: int64"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking distribution of column 'cried during a movie'\n",
    "dataset.iloc[:, 464].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "5184addd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# I will divide into two groups by median rate(3.0)\n",
    "# I won't be using 3.0 as it is a median rate, and assume 6.0 as high rate\n",
    "\n",
    "# Filter by people watching movies alone or watching socially\n",
    "movies_cry = dataset[dataset.iloc[:, 464] > 3.0].iloc[:, :400]\n",
    "movies_dont_cry = dataset[dataset.iloc[:, 464] < 3.0].iloc[:, :400]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "e1c26031",
   "metadata": {},
   "outputs": [],
   "source": [
    "# small: reject null hypothesis, so effective\n",
    "# big: don't reject null hypothesis, so not effective \n",
    "# len(dataset_male.columns) == len(dataset_female.columns) == 400\n",
    "\n",
    "# iterate by each movies and calculate p-value\n",
    "# for each male and female ratings, drop null values element-wise and compare \n",
    "# if p-value is relatively small(p < 0.005), add count to small\n",
    "# if p-value is relatively big(p >= 0.005), add count to big\n",
    "\n",
    "small = 0\n",
    "big = 0\n",
    "\n",
    "for i in range(len(movies_cry.columns)):\n",
    "    cried = movies_cry.iloc[:,i]\n",
    "    cried = cried[pd.notnull(cried)]\n",
    "    \n",
    "    not_cried = movies_dont_cry.iloc[:,i]\n",
    "    not_cried = not_cried[pd.notnull(not_cried)]\n",
    "    \n",
    "    u1, p1 = stats.mannwhitneyu(cried, not_cried)\n",
    "    \n",
    "    if p1 < 0.005:\n",
    "        small += 1\n",
    "    else:\n",
    "        big += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "a600fa44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "small p-values: 17, big p-values: 383, proportion:0.0425\n"
     ]
    }
   ],
   "source": [
    "# Calculate proportion\n",
    "proportion = small / (small+big)\n",
    "print('small p-values: {0}, big p-values: {1}, proportion:{2}'.format(small, big, proportion))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a677270d",
   "metadata": {},
   "source": [
    "<p style='font-weight:bold; font-size:18px'> Extra - (3) </p>\n",
    "<p style='font-size:16px'> Let's assume that people who rates over the limit tends to rate differently than people who don't. </p>\n",
    "<p style='font-size:16px'> If we call this \"outlier effect\", proportion of movies rated differently by \"outlier effect\" is 0.05</p>\n",
    "\n",
    "<p style='font-weight:bold; font-size:18px'> Explanation) </p>\n",
    "<p style='font-size:16px'> I've checked questions that people gave wrong answers. (Which is, over the 1.0 ~ 5.0 range). Then, I've selected column that has the most wrong answers(outliers).</p>\n",
    "<p style='font-size:16px'> Then, I've divided groups into outliers and normal ratings.</p><br>\n",
    "\n",
    "\n",
    "<p style='font-size:16px'> I will apply below null hypothesis testing to each movies and calculate proportion of movies that have relatively small p-value. If p-value is relatively small, I can conclude that given movie is rated differently by viewers with outliers and normal.</p>\n",
    "\n",
    "<p style='font-size:16px'> Hypothesis: Given movie is rated differently by people rates wrongly or normally.</p>\n",
    "<p style='font-size:16px'> Null hypothesis: Given movie is not rated differently by people wrongly or normally.</p>\n",
    "<p style='font-size:16px'> I will assume that the null hypothesis is true</p><br>\n",
    "\n",
    "<p style='font-size:16px'>  I divided viewers into people who rated over the limit for [column 470: The emotions on the screen \"rub off\" on me] and those who didn't. Then for each movies, I've conducted Mann-Whitney U test and caclulated p-value. I am using  Mann-Whitney U test test since I am comparing 2 groups that are nonparametric, and movie ratings data is ordinal data.</p><br>\n",
    "\n",
    "<p style='font-size:16px'> By classifying p-value based on significant level a=0.005, I got 20 movies with relatively small p-values, and 380 movies with relatively big p-values.</p>\n",
    "\n",
    "<p style='font-size:16px'> Therefore, proportion of movies rated differently by \"outlier effect\" is 0.05</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "f003a21f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column 464: I have cried during a movie ~ has 98 outliers\n",
      "Column 465: I have trouble following the story of a movie ~ has 10 outliers\n",
      "Column 466: I have trouble remembering the story of a movie a  ~ has 18 outliers\n",
      "Column 467: When watching a movie I cheer or shout or talk or  ~ has 46 outliers\n",
      "Column 468: When watching a movie I feel like the things on th ~ has 41 outliers\n",
      "Column 469: As a movie unfolds I start to have problems keepin ~ has 15 outliers\n",
      "Column 470: The emotions on the screen \"rub off\" on me - for i ~ has 226 outliers\n",
      "Column 471: When watching a movie I get completely immersed in ~ has 164 outliers\n",
      "Column 472: Movies change my position on social economic or po ~ has 30 outliers\n",
      "Column 473: When watching movies things get so intense that I  ~ has 14 outliers\n"
     ]
    }
   ],
   "source": [
    "# Selecting column 470, since it has the most outliers (column 470 has 226 outliers)\n",
    "for i in range(400, 474):\n",
    "    outlier = dataset.iloc[:, i][dataset.iloc[:, i] > 5.0].count()\n",
    "    if outlier > 0:\n",
    "        print('Column {0}: {1:.50} ~ has {2} outliers'.format(i, dataset.columns[i], outlier))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "9754cb4e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5.0    348\n",
       "4.0    303\n",
       "6.0    226\n",
       "3.0    120\n",
       "1.0     44\n",
       "2.0     34\n",
       "Name: The emotions on the screen \"rub off\" on me - for instance if something sad is happening I get sad or if something frightening is happening I get scared, dtype: int64"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking distribution of outlier column\n",
    "dataset.iloc[:, 470].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "608817c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter by people watching movies alone or watching socially\n",
    "rating_outlier = dataset[dataset.iloc[:, 470] > 5.0].iloc[:, :400]\n",
    "rating_normal = dataset[dataset.iloc[:, 470] < 5.0].iloc[:, :400]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "f070d2af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# small: reject null hypothesis, so effective\n",
    "# big: don't reject null hypothesis, so not effective \n",
    "# len(dataset_male.columns) == len(dataset_female.columns) == 400\n",
    "\n",
    "# iterate by each movies and calculate p-value\n",
    "# for each male and female ratings, drop null values element-wise and compare \n",
    "# if p-value is relatively small(p < 0.005), add count to small\n",
    "# if p-value is relatively big(p >= 0.005), add count to big\n",
    "\n",
    "small = 0\n",
    "big = 0\n",
    "\n",
    "for i in range(len(rating_outlier.columns)):\n",
    "    outlier = rating_outlier.iloc[:,i]\n",
    "    outlier = outlier[pd.notnull(outlier)]\n",
    "    \n",
    "    normal = rating_normal.iloc[:,i]\n",
    "    normal = normal[pd.notnull(normal)]\n",
    "    \n",
    "    u1, p1 = stats.mannwhitneyu(outlier, normal)\n",
    "    \n",
    "    if p1 < 0.005:\n",
    "        small += 1\n",
    "    else:\n",
    "        big += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "d382e886",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "small p-values: 20, big p-values: 380, proportion:0.05\n"
     ]
    }
   ],
   "source": [
    "# Calculate proportion\n",
    "proportion = small / (small+big)\n",
    "print('small p-values: {0}, big p-values: {1}, proportion:{2}'.format(small, big, proportion))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
