{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b1a4afe9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['10 things I hate about you (1999)', '12 Monkeys (1995)',\n",
      "       '13 going on 30 (2004)', '21 Grams (2003)', '25th hour (2002)',\n",
      "       '28 days later (2002)', '3000 Miles to Graceland (2001)',\n",
      "       '8 Mile (2002)', 'A Night at the Roxbury (1998) ',\n",
      "       'A time to kill (1996)',\n",
      "       ...\n",
      "       'Toy Story (1995)', 'Toy Story 2 (1999)', 'Unforgiven (1992)',\n",
      "       'What Lies Beneath (2000)', 'What Women Want (2000)',\n",
      "       'Wild Wild West (1999)', 'Wing Commander (1999)', 'X-Men (2000)',\n",
      "       'X2 (2003)', 'Zoolander (2001)'],\n",
      "      dtype='object', length=209)\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 120 entries, 0 to 119\n",
      "Data columns (total 3 columns):\n",
      " #   Column  Non-Null Count  Dtype  \n",
      "---  ------  --------------  -----  \n",
      " 0   Value   120 non-null    float64\n",
      " 1   X1      120 non-null    int64  \n",
      " 2   X2      120 non-null    int64  \n",
      "dtypes: float64(1), int64(2)\n",
      "memory usage: 2.9 KB\n",
      "                sum_sq     df             F        PR(>F)\n",
      "X1        2.999991e+01    1.0  7.592603e+00  6.807788e-03\n",
      "X2        1.199999e+02    1.0  3.037049e+01  2.184996e-07\n",
      "X1:X2     6.600833e-11    1.0  1.670589e-11  9.999967e-01\n",
      "Residual  4.583395e+02  116.0           NaN           NaN\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "# ### Lab04\n",
    "# \n",
    "# ### 2021-09-23\n",
    "\n",
    "# ### Statistical significance tests on real data\n",
    "\n",
    "\n",
    "#%% In this script, we will analyze real data from a published article (Wallisch & Whritner 2017)\n",
    "# A subset of it. The point is specifically to illustrate hypothesis testing \n",
    "# in Python and to implement the Canonical Data Analysis cascade. \n",
    "# The advantage of this is that you'll be free of the limitations of canned\n",
    "# packages like Excel or SPSS. \n",
    "# Specifically, we will test the hypothesis that Matrix I was the best of\n",
    "# the Matrix movies (it's a trilogy). \n",
    "                    \n",
    "# Since we are doing this here, let me walk you through the null hypothesis\n",
    "# testing framework at least once (just once). It is a bit arcane. It made\n",
    "# sense to Fisher.                  \n",
    "                    \n",
    "# 1) Start with a hypothesis (something about the world you would wish to\n",
    "# know, whether it is true or not. The participants are just the unit of \n",
    "# analysis that gives you the data). \n",
    "\n",
    "# 2) State a null hypothesis and assume that it is 100% true (that there is\n",
    "# no difference in the conditions of 1), e.g. here Matrix I rated the same\n",
    "# as Matrix II and III). This is essential to NHST. \n",
    "\n",
    "# 3) This is - at the face of it - an odd thing to do, because naively you\n",
    "# would think that scientists look for probability (Hypothesis | Data) \n",
    "# But that is unknowable. Which is why we do the study in the first place\n",
    "# What is calculable: Probability (Data | NULL hypothesis)\n",
    "# You can assess the probability of the data given the null hypothesis\n",
    "\n",
    "# 4) To get this probability, we represent the sample by a parameter like a \n",
    "# sample mean, then transform the sample mean into a test statistic with a \n",
    "# known distribution.\n",
    "\n",
    "# 5) The area under the curve of the distribution of the test statistic in\n",
    "# the tail (or tails, if it is a 2-tailed test) is the p value, in other\n",
    "# words the probability of this result (or a more extreme one) given chance\n",
    "# alone.\n",
    "\n",
    "# 6) We compare the p value to a significance level alpha (typically 5% or 1%)\n",
    "\n",
    "# 7) Decision point (Choice)\n",
    "# a) If it is smaller than that, we decide to reject our assumption that the \n",
    "# null hypothesis is true.\n",
    "# b) If it is not smaller than that, we don't do anything because we already\n",
    "# assumed that the null hypothesis is true.                    \n",
    "                    \n",
    "# Paraphrased logic, in english: We acknowledge any outcome could be due to\n",
    "# chance. Our only question is how likely that is by chance. If it is\n",
    "# implausibly unlikely, we reject the assumption that it was just due to\n",
    "# chance. And either the null hypothesis is true or not, so if we reject it\n",
    "# is plausible, it probably means that our treatment did have an effect.                  \n",
    "                    \n",
    "#%% Before we do the stats, let's talk about the psychology of movie ratings:\n",
    "    \n",
    "# Hypothesis 1: First is best. Because that's usually true for trilogies\n",
    "# (with the exception of Star Wars). That's probably true just because of\n",
    "# regression to the mean. Also expectations. If the first one is great, it's\n",
    "# hard to beat expectations. \n",
    "\n",
    "# Hypothesis 2: Ratings for later ones will be even better. Production\n",
    "# qualities improve over time. Also, only fans might watch all of them.\n",
    "# People who didn't like the 1st one might drop out and never watch the\n",
    "# other ones, so the RATINGS might appear higher. \n",
    "\n",
    "# Make sure that you actually have 2 plausible outcomes before doing the\n",
    "# study. If the outcome is a foregone conclusion, it's not science. Science\n",
    "# is about being open to any possible outcome.\n",
    "\n",
    "# Null hypothesis: There is no difference. \n",
    "\n",
    "# Let's implement the canonical data analysis cascade\n",
    "\n",
    "#%% 0 Init (Birth)\n",
    "\n",
    "# a. Predispositions:\n",
    "startColumn = 177 # This is the column that contains data from matrix I\n",
    "# matrix II is column 178 and matrix III is column 179\n",
    "numMovies = 3 # Data from how many movies (it's a trilogy)\n",
    "pruningMode = 2 # This flag determines how we will remove nans. It's important to be mindful of this \n",
    "# 1 = element-wise, 2 = row-wise, 3 = imputation\n",
    "\n",
    "# b. Load/import - libraries/packages:\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#%% 1 Loader / Transducer: \n",
    "# Taking the inputs from their native form and putting it into \n",
    "# something Python can use: a matrix\n",
    "\n",
    "data = np.genfromtxt('movieRatingsDeidentified.csv', delimiter = ',', skip_header = 1)\n",
    "# We want just the data, so skip the first row / header\n",
    "dataMatrix = data[:,startColumn:startColumn+numMovies] # Should yield a n x 3 matrix\n",
    "\n",
    "# Decompose data_matrix into separate arrays, one for each movie:\n",
    "M1 = dataMatrix[:,0]\n",
    "M2 = dataMatrix[:,1]\n",
    "M3 = dataMatrix[:,2]\n",
    "# They are all the same length because if the participant did not respond\n",
    "# the element is represented with NaN\n",
    "\n",
    "#%% 2 \"Thalamus\" stage: We need to get rid of \"bad\" data. \n",
    "\n",
    "# This is not data we don't like the results of. \n",
    "# It's data that if it entered the analysis stream would ruin our analysis\n",
    "\n",
    "# By visual inspection, the matrix of movie ratings contains numbers from 1\n",
    "# to 4, representing \"star ratings\", and \"nans\". \n",
    "# What could the nans be? What do they mean?\n",
    "# It could be people not doing the task. There are many ways to detect this.\n",
    "# People who press buttons not in the instructions, people responding too\n",
    "# fast, people responding too slow. \n",
    "\n",
    "# Why might \"too slow\" be a problem? In one study, we were interested in\n",
    "# reaction time as a dependent variable. But once, a participant went to the\n",
    "# restroom in the middle of the experiment and didn't come back for 30\n",
    "# minutes. What would happen to the mean reaction time for the condition\n",
    "# that the trial was in, in which this participant used the restroom. If we\n",
    "# included this, it would be meaningless. The mean is sensitive to outliers.\n",
    "# The rest of the reactions are in milli-seconds. This is 4 orders of\n",
    "# magnitude higher. Another example from neuroscience: Voltages of\n",
    "# electrodes are usually in mV or microV (depending on eeg vs.\n",
    "# microelectrode). What if for one trial there was voltage surge that hit\n",
    "# the building - all measurements from that trial are invalid. You need to\n",
    "# exclude that BEFORE looking at the results. All results will be thrown off\n",
    "# by that.\n",
    "\n",
    "# Given that these are movie ratings, it is not implausible that most of\n",
    "# these nans represent missing data due to the participant did not watch the\n",
    "# movie in question. \n",
    "# The reason we have to deal with this is that once this data is in the\n",
    "# analysis stream, it will make the rest of the interpretation hard. If\n",
    "# there is a single nan in the data, we can't take the mean. \n",
    "# So \"filtering\" or removing of ill-formed data will mean \"removal of\n",
    "# missing data\" in this case.\n",
    "# But here is the catch: Remove them how?\n",
    "\n",
    "# There are at least 3 ways to handle this, and depending on how we do this,\n",
    "# it will set up the entire rest of the analysis (and what it means). \n",
    "\n",
    "# 1) Element-wise removal of nans: We remove nans from each data matrix\n",
    "# where we find it. But we are starting with an equal n for each movie. 3204\n",
    "# rows in all 3 matrices. Once we start removing stuff element-wise, due to\n",
    "# the fact that there are an unequal number of nans for each movie, this\n",
    "# will result in unequal n, which will make some analyses impossible. Some\n",
    "# analyses presume equal n. It could also introduce bias. If we remove\n",
    "# people who have not seen the latter ones, but that was a choice (their\n",
    "# choice), we would inflate the ratings artificially. \n",
    "\n",
    "# 2) Row-wise (participant-wise) removal of nans: If a participant has not\n",
    "# seen even one of the movies, we remove all of the data from this\n",
    "# participant. Good: We keep n the same. Bad: We will lose a lot of data.\n",
    "# Probably most of the data. This usually looks suspicious, also: Loss of\n",
    "# statistical power. \n",
    "\n",
    "# 3) Imputation: We replace the missing data with our guess of what the \n",
    "# rating would have been, if there had been a rating. \n",
    "# This is more commonly done in engineering than in science. \n",
    "# Sometimes, people replace the missing value with the mean. But which mean?\n",
    "# The participant-wise mean or the movie-wise mean - or a blend of the two? \n",
    "# We could do the average of the movie, but is that fair? Those people chose\n",
    "# not to watch it - they were not randomly assigned to watch the movies.\n",
    "# This suggests that their rating would have been lower than that average.\n",
    "# But how much lower? 0? Probably too extreme. \n",
    "# In science, data only comes from measurement\n",
    "\n",
    "# In real life, pick the option that makes the most sense for your\n",
    "# theoretical approach, and just do that. For teaching purposes, we'll do\n",
    "# all of them, just so you see how that plays out in real life.\n",
    "\n",
    "# 1) Element-wise:\n",
    "if pruningMode == 1:\n",
    "   M1 = M1[np.isfinite(M1)] # only keep the finite elements (not infinity or NaN)\n",
    "   M2 = M2[np.isfinite(M2)] # only keep the finite elements (not infinity or NaN)\n",
    "   M3 = M3[np.isfinite(M3)] # only keep the finite elements (not infinity or NaN)\n",
    "# Outcome: Exactly as we suspected, n is unequal now, and we have concerns\n",
    "# about the psychological interpretation of this, as we only have the\n",
    "# ratings of die-hard fans who watched all 3 for the third one.\n",
    "\n",
    "# 2) Row wise:\n",
    "elif pruningMode == 2:\n",
    "    temp = np.array([np.isnan(M1),np.isnan(M2),np.isnan(M3)],dtype=bool)\n",
    "    temp2 = temp*1 # convert boolean to int\n",
    "    temp2 = sum(temp2) # take sum of each participant\n",
    "    missingData = np.where(temp2>0) # find participants with missing data\n",
    "    M1 = np.delete(M1,missingData) # delete missing data from array\n",
    "    M2 = np.delete(M2,missingData) # delete missing data from array\n",
    "    M3 = np.delete(M3,missingData) # delete missing data from array\n",
    "# Good: We have equal n now. \n",
    "# Bad: We only have 1493 out of 3204 we started with left\n",
    "# That is a) suspicious, b) we lost a lot of power\n",
    "\n",
    "#%% 3 Reformatting - V1: Format data into a representation to work with\n",
    "\n",
    "# I did most of the work for you already. In preprocessing. In other words,\n",
    "# I took the records that came in over time by participant and broke them\n",
    "# up, so they are now ordered by movie. I already abstracted over time.\n",
    "# There is still something we can do that will make our life easier, which\n",
    "# is to put this into a format we can loop over (to do all these tests). Why\n",
    "# is the current format not great? M1 vs. M3, etc. is not great for that?\n",
    "# Wouldn't it be better to have a matrix \"DATA\" that contains all 3 movies?\n",
    "# It would be. Why can't it be a matrix now, given we removed missing data\n",
    "# element-wise? Because n is unequal. So let's make it an array of arrays\n",
    "\n",
    "if pruningMode == 1:\n",
    "    combinedData = np.transpose(np.array([M1,M2,M3])) # array of arrays\n",
    "elif pruningMode == 2:\n",
    "    combinedData = np.transpose(np.array([M1,M2,M3])) # 2D array\n",
    "    # We can now put the data into a 2D array because we have an equal number\n",
    "    # of rows for M1, M2 and M3\n",
    "    \n",
    "#%% 4a) Extrastriate cortex: Doing the actual specialized analyses\n",
    "# Descriptive statistics - we are looking for very special numbers that\n",
    "# capture the essence of the entire dataset - the typical number (central\n",
    "# tendency) and the dispersion. Typically mean and SD. \n",
    "\n",
    "# Initialize container to store descriptives:\n",
    "descriptivesContainer = np.empty([numMovies,4])\n",
    "descriptivesContainer[:] = np.NaN \n",
    "\n",
    "# 1. Element-wise:\n",
    "if pruningMode == 1:\n",
    "    for ii in range(numMovies):\n",
    "        descriptivesContainer[ii,0] = np.mean(combinedData[ii]) # mu\n",
    "        descriptivesContainer[ii,1] = np.std(combinedData[ii]) # sigma\n",
    "        descriptivesContainer[ii,2] = len(combinedData[ii]) # n\n",
    "        descriptivesContainer[ii,3] = descriptivesContainer[ii,1]/np.sqrt(descriptivesContainer[ii,2]) # sem\n",
    "\n",
    "# 2. Row-wise:\n",
    "elif pruningMode == 2:\n",
    "    for ii in range(numMovies):\n",
    "        descriptivesContainer[ii,0] = np.mean(combinedData[:,ii]) # mu\n",
    "        descriptivesContainer[ii,1] = np.std(combinedData[:,ii]) # sigma\n",
    "        descriptivesContainer[ii,2] = len(combinedData[:,ii]) # n\n",
    "        descriptivesContainer[ii,3] = descriptivesContainer[ii,1]/np.sqrt(descriptivesContainer[ii,2]) # sem\n",
    "        \n",
    "#%% 4b) Extrastriate cortex part II: Inferential statistics\n",
    "\n",
    "# So far, so good. The mean rating of matrix 1 is higher than that of matrix\n",
    "# 2, and the mean of matrix 2 is higher than matrix 3. \n",
    "\n",
    "# The question here is whether the differences we saw in the descriptives -\n",
    "# usually the means - are \"statistically significant\". \n",
    "# Whether it is plausibly consistent with chance (that the numbers came out\n",
    "# of a RGN)\n",
    "\n",
    "# 1) Assert a null hypothesis: We assume that the data came out of a RNG -\n",
    "# strictly by chance.\n",
    "\n",
    "# 2) We compute the probability that this is the case - assuming chance. \n",
    "\n",
    "# 3) If this probability is implausibly low, we DECIDE to concede that we\n",
    "# were wrong in 1) - that it is probably not solely due to chance. \n",
    "\n",
    "# It's a choice, it's a decision. You have not falsified the null hypothesis\n",
    "# or \"proven\" to be wrong. We made a choice that it is implausible. But we\n",
    "# could be wrong (type I and type II errors). \n",
    "\n",
    "# In science, we consider things that happen only 1 in 20 times to be \"too\n",
    "# implausible\" to be consistent with chance. This corresponds to getting\n",
    "# heads (or tails) 5 times in a row (if you flip coins). Is that terribly\n",
    "# implausible? There is now a movement afoot to lower this to 1 in 200. To\n",
    "# avoid false positives. So results won't reproduce. This gave p values a\n",
    "# bad reputation. But there is nothing wrong with them, if they are\n",
    "# understood and used properly. Properly = conservative enough criterion of\n",
    "# implausibility and high enough power. \n",
    "\n",
    "# So our question now is: Assuming that there is no difference in reality, how\n",
    "# likely is it to get this mean difference just by chance (sampling error).    \n",
    "\n",
    "# Analogy: We are doing a crime scene investigation. Null hypothesis is the\n",
    "# presumption of innocence. We only reject that presumption if forced by the\n",
    "# data (in other words, if the evidence suggests that the fingerprints, DNA,\n",
    "# etc.) of the suspect didn't just get there by chance. It is always\n",
    "# possible. The unreasonable doubt (that your evidence got there just by\n",
    "# chance always persists). \n",
    "\n",
    "# We need to do a t-test because we want to assess how likely this observed\n",
    "# mean difference is and we do not know the population parameters. We have\n",
    "# to do an independent samples t-test because we eliminated missing data in a \n",
    "# way to yield unequal n. We have no choice (if we want to do a t-test)\n",
    "\n",
    "# 1. Element-wise:\n",
    "if pruningMode == 1:\n",
    "    t1,p1 = stats.ttest_ind(combinedData[0],combinedData[1])\n",
    "    # There is a significant difference. \n",
    "    # In english: The difference between the samples (specifically the sample \n",
    "    # means) is too large to be reasonably consistent with chance. \n",
    "\n",
    "    # Now let's compute the degrees of freedom (N1 + N2 - 2):\n",
    "    df = int(descriptivesContainer[0,2] + descriptivesContainer[1,2] - 2)\n",
    "\n",
    "    # How likely was our mean difference assuming chance? \n",
    "    # The p-value is really small. 5% is an extremely liberal threshold.\n",
    "    # p-values of real effects are very close to 0, if you have sufficient\n",
    "    # power. They are distributed as a beta-distribution. Like this one.\n",
    "\n",
    "    # Degrees of freedom for an independent samples t-test is:\n",
    "    # Sample size1 + sample size2 - 2 (2 because we calculate 2 sample means and\n",
    "    # we lose 1 df per sample mean). So the general equation for df is not n -\n",
    "    # 1, it is n - k. \n",
    "\n",
    "    # The independent samples t-test is the only one we can do, once we have\n",
    "    # unequal n, but is it the right test? Did the data about the 2 movies come\n",
    "    # from different populations? No. They are the same people. In reality, we\n",
    "    # probably have much less df. \n",
    "\n",
    "    # Mean of Matrix 2 and 3 seem rather close. Question: Plausibly due to chance\n",
    "    # (sampling error) alone?\n",
    "    t2,p2 = stats.ttest_ind(combinedData[1],combinedData[2])\n",
    "\n",
    "    # We can do as many t-tests as we want. We will have to adjust the\n",
    "    # alpha-level from 0.05 to 0.05/c, where c is the number of tests\n",
    "    # (comparisons), that's called the \"Bonferroni correction\". \n",
    "\n",
    "    # Even this comparison is significant, even after the Bonferroni correction,\n",
    "    # so we conclude that this observed difference in ratings is not due to\n",
    "    # chance alone. In other words, Matrix 2 is a better movie than Matrix 3. \n",
    "    # Expectation: The p-value will be even lower than 1 vs. 2, because the\n",
    "    # mean difference is larger, but it might not be, because the df will be\n",
    "    # less (fewer people saw M3). The p value comes from the t-value in light of\n",
    "    # the df (because the t-distribution is a family of distributions which\n",
    "    # differs as df - that's a parameter).\n",
    "    t3,p3 = stats.ttest_ind(combinedData[0],combinedData[2])\n",
    "\n",
    "    # Do this with ANOVA - allows to compare more than 2 sample means without \n",
    "    # inflating alpha (from multiple comparisons)\n",
    "    f,p = stats.f_oneway(combinedData[0],combinedData[1],combinedData[2])\n",
    "    \n",
    "    # Nonparametric tests equivalent to t-tests - Mann-Whitney U test:\n",
    "    # Test for comparing medians of ordinal data (such as movie ratings)\n",
    "    # from 2 groups\n",
    "    u1,p1 = stats.mannwhitneyu(combinedData[0],combinedData[1])\n",
    "    u2,p2 = stats.mannwhitneyu(combinedData[0],combinedData[2])\n",
    "    u3,p3 = stats.mannwhitneyu(combinedData[1],combinedData[2])\n",
    "\n",
    "    # Nonparametric tests equivalent to ANOVA - Kruskal-Wallis:\n",
    "    # Same assumptions as above, but for more than 2 groups\n",
    "    h,p = stats.kruskal(combinedData[0],combinedData[1])\n",
    "    \n",
    "    \n",
    "\n",
    "# These are not different people. So we have to do a \"within subjects\"\n",
    "# design (repeated measures) - in other words do a paired samples t-test. \n",
    "# But to do that, we need to do row-wise removal of missing data \n",
    "\n",
    "# 2. Row-wise:\n",
    "elif pruningMode == 2:\n",
    "    # Because our n's are now equal, we can now do a t-test for dependent\n",
    "    # groups (which is much more appropriate, because our data came from the\n",
    "    # *same* people, the groups WERE dependent, we previously inflated df)\n",
    "    t1,p1 = stats.ttest_rel(combinedData[:,0],combinedData[:,1])\n",
    "    df = len(combinedData) - 1\n",
    "    # Df HERE is now n-1, because the t-test for dependent groups first\n",
    "    # converts all scores to differences, then takes ONE mean, so we only\n",
    "    # lose 1 df. Overall, we have much fewer df, than in the independent\n",
    "    # samples t-test.\n",
    "    # The p-value is even lower. How is that possible, given that df is\n",
    "    # lower too? \n",
    "    # In an independent samples t-test individual differences (some people\n",
    "    # just don't like anything, or everything) all goes into the\n",
    "    # denominator, in other words is interpreted as error. That lowers the\n",
    "    # t-value. In a paired-samples t-test, everyone is their own control. So\n",
    "    # the individual differences go away. In english: A paired samples\n",
    "    # t-test is usually much more powerful, even if the df is lower. So you\n",
    "    # should do this one, whenever you can. \n",
    "    t2,p2 = stats.ttest_rel(combinedData[:,1],combinedData[:,2])\n",
    "    t3,p3 = stats.ttest_rel(combinedData[:,0],combinedData[:,2])\n",
    "    \n",
    "    # Let's do an ANOVA instead:\n",
    "    f,p = stats.f_oneway(combinedData[:,0],combinedData[:,1],combinedData[:,2])\n",
    "    \n",
    "#%% 5 Motor cortex: Plot the data \n",
    "# Here we are going to plot the data from our ANOVA and add a title\n",
    "# that contains the f- and p-values\n",
    "\n",
    "# First, let's run our ANOVA once again:\n",
    "if pruningMode == 1:\n",
    "    f,p = stats.f_oneway(combinedData[0],combinedData[1],combinedData[2])\n",
    "elif pruningMode == 2:\n",
    "    f,p = stats.f_oneway(combinedData[:,0],combinedData[:,1],combinedData[:,2])\n",
    "    \n",
    "# Now, let's plot it:\n",
    "x = ['Matrix 1', 'Matrix 2', 'Matrix 3'] # labels for the bars\n",
    "xPos = np.array([1,2,3]) # x-values for the bars\n",
    "plt.bar(xPos,descriptivesContainer[:,0],width=0.5,yerr=descriptivesContainer[:,3]) # bars + error  \n",
    "plt.xticks(xPos, x) # label the x_pos with the labels\n",
    "plt.ylabel('Mean rating') # add y-label\n",
    "plt.title('f = {:.3f}'.format(f) + ', p = {:.3f}'.format(p)) # title is the test stat and p-value\n",
    "# Note: we round our p-value to the nearest thousandth, which in our case is 0.000\n",
    "# In reality, it is much smaller than that. Instead, we could have chosen to use\n",
    "# scientific notation in our title. More on that later.\n",
    "\n",
    "#%% Supplementary material 1: Representing the data with a Pandas dataframe and doing a 2-way ANOVA in Python and make an ANOVA table (and a means plot)\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# 1. Load data:\n",
    "df = pd.read_csv('movieRatingsDeidentified.csv',skipinitialspace=True)\n",
    "# Fill empty strings with NaN\n",
    "# Now we have the headers AND the data in one object\n",
    "# This is a DataFrame. For handling tabular data.\n",
    "\n",
    "# 2. Let's get a handle on our movie titles:\n",
    "titles = df.columns \n",
    "print(titles)\n",
    "# We won't use this for subsequent analyses, but it's nice to see all the titles at once\n",
    "\n",
    "# 3. Find the Matrix data:\n",
    "title = 'Matrix' # or any other title, for that matter\n",
    "theMatrix = df.loc[:,df.columns.str.contains(title)]\n",
    "\n",
    "# 4. Perform descriptives:\n",
    "magic = theMatrix.describe()\n",
    "# We don't have to run a loop or initialize a container\n",
    "# We are still missing the SEM, so let's add it:\n",
    "temp = magic.iloc[2,:]/np.sqrt(magic.iloc[0,:])\n",
    "magic.loc['sem'] = temp\n",
    "\n",
    "#%% Supplementary material 2: Do a two-way ANOVA and show an ANOVA table\n",
    "\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.formula.api import ols\n",
    "from statsmodels.graphics.factorplots import interaction_plot as meansPlot\n",
    "\n",
    "df = pd.read_csv('twoWayAnovaExample.csv',skipinitialspace=True) # load new data set\n",
    "df.info() # What is the structure of the data frame?\n",
    "\n",
    "model = ols('Value ~ X1 + X2 + X1:X2', data=df).fit() #Build the two-way ANOVA model. Value = y, X1,X2 = Main effects. X1:X2 = interaction effect\n",
    "anova_table = sm.stats.anova_lm(model, typ=2) #Create the ANOVA table. Residual = Within\n",
    "print(anova_table) #Show the ANOVA table\n",
    "\n",
    "#Show the corresponding means plot\n",
    "fig = meansPlot(x=df['X1'], trace=df['X2'], response=df['Value'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "fdb37f15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# a. Predispositions:\n",
    "startColumn = 177 # This is the column that contains data from matrix I\n",
    "# matrix II is column 178 and matrix III is column 179\n",
    "numMovies = 3 # Data from how many movies (it's a trilogy)\n",
    "pruningMode = 2 # This flag determines how we will remove nans. It's important to be mindful of this \n",
    "# 1 = element-wise, 2 = row-wise, 3 = imputation\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import stats\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#%% 1 Loader / Transducer: \n",
    "# Taking the inputs from their native form and putting it into \n",
    "# something Python can use: a matrix\n",
    "\n",
    "data = np.genfromtxt('movieRatingsDeidentified.csv', delimiter = ',', skip_header = 1)\n",
    "# We want just the data, so skip the first row / header\n",
    "dataMatrix = data[:,startColumn:startColumn+numMovies] # Should yield a n x 3 matrix\n",
    "\n",
    "# Decompose data_matrix into separate arrays, one for each movie:\n",
    "M1 = dataMatrix[:,0]\n",
    "M2 = dataMatrix[:,1]\n",
    "M3 = dataMatrix[:,2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "f7a9ef65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1) Element-wise:\n",
    "if pruningMode == 1:\n",
    "   M1 = M1[np.isfinite(M1)] # only keep the finite elements (not infinity or NaN)\n",
    "   M2 = M2[np.isfinite(M2)] # only keep the finite elements (not infinity or NaN)\n",
    "   M3 = M3[np.isfinite(M3)] # only keep the finite elements (not infinity or NaN)\n",
    "# Outcome: Exactly as we suspected, n is unequal now, and we have concerns\n",
    "# about the psychological interpretation of this, as we only have the\n",
    "# ratings of die-hard fans who watched all 3 for the third one.\n",
    "\n",
    "# 2) Row wise:\n",
    "elif pruningMode == 2:\n",
    "    temp = np.array([np.isnan(M1),np.isnan(M2),np.isnan(M3)],dtype=bool)\n",
    "    temp2 = temp*1 # convert boolean to int\n",
    "    temp2 = sum(temp2) # take sum of each participant\n",
    "    missingData = np.where(temp2>0) # find participants with missing data\n",
    "    M1 = np.delete(M1,missingData) # delete missing data from array\n",
    "    M2 = np.delete(M2,missingData) # delete missing data from array\n",
    "    M3 = np.delete(M3,missingData) # delete missing data from array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "8be105e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "if pruningMode == 1:\n",
    "    combinedData = np.transpose(np.array([M1,M2,M3])) # array of arrays\n",
    "elif pruningMode == 2:\n",
    "    combinedData = np.transpose(np.array([M1,M2,M3])) # 2D array\n",
    "    # We can now put the data into a 2D array because we have an equal number\n",
    "    # of rows for M1, M2 and M3\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "59ec8e1d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([3.5, 0.5, 0.5]), array([4., 4., 4.]))"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combinedData[0], combinedData[1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "db1d877e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((3,), (3,))"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combinedData[0].shape, combinedData[1].shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "950b1c18",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.0, 0.05934643879191985)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "u1, p1 = stats.mannwhitneyu(combinedData[0],combinedData[1])\n",
    "u1, p1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "7181fcc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize container to store descriptives:\n",
    "descriptivesContainer = np.empty([numMovies,4])\n",
    "descriptivesContainer[:] = np.NaN \n",
    "\n",
    "# 1. Element-wise:\n",
    "if pruningMode == 1:\n",
    "    for ii in range(numMovies):\n",
    "        descriptivesContainer[ii,0] = np.mean(combinedData[ii]) # mu\n",
    "        descriptivesContainer[ii,1] = np.std(combinedData[ii]) # sigma\n",
    "        descriptivesContainer[ii,2] = len(combinedData[ii]) # n\n",
    "        descriptivesContainer[ii,3] = descriptivesContainer[ii,1]/np.sqrt(descriptivesContainer[ii,2]) # sem\n",
    "\n",
    "# 2. Row-wise:\n",
    "elif pruningMode == 2:\n",
    "    for ii in range(numMovies):\n",
    "        descriptivesContainer[ii,0] = np.mean(combinedData[:,ii]) # mu\n",
    "        descriptivesContainer[ii,1] = np.std(combinedData[:,ii]) # sigma\n",
    "        descriptivesContainer[ii,2] = len(combinedData[:,ii]) # n\n",
    "        descriptivesContainer[ii,3] = descriptivesContainer[ii,1]/np.sqrt(descriptivesContainer[ii,2]) # sem\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "9dde37dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Element-wise:\n",
    "if pruningMode == 1:\n",
    "    t1,p1 = stats.ttest_ind(combinedData[0],combinedData[1])\n",
    "    # There is a significant difference. \n",
    "    # In english: The difference between the samples (specifically the sample \n",
    "    # means) is too large to be reasonably consistent with chance. \n",
    "\n",
    "    # Now let's compute the degrees of freedom (N1 + N2 - 2):\n",
    "    df = int(descriptivesContainer[0,2] + descriptivesContainer[1,2] - 2)\n",
    "\n",
    "    # How likely was our mean difference assuming chance? \n",
    "    # The p-value is really small. 5% is an extremely liberal threshold.\n",
    "    # p-values of real effects are very close to 0, if you have sufficient\n",
    "    # power. They are distributed as a beta-distribution. Like this one.\n",
    "\n",
    "    # Degrees of freedom for an independent samples t-test is:\n",
    "    # Sample size1 + sample size2 - 2 (2 because we calculate 2 sample means and\n",
    "    # we lose 1 df per sample mean). So the general equation for df is not n -\n",
    "    # 1, it is n - k. \n",
    "\n",
    "    # The independent samples t-test is the only one we can do, once we have\n",
    "    # unequal n, but is it the right test? Did the data about the 2 movies come\n",
    "    # from different populations? No. They are the same people. In reality, we\n",
    "    # probably have much less df. \n",
    "\n",
    "    # Mean of Matrix 2 and 3 seem rather close. Question: Plausibly due to chance\n",
    "    # (sampling error) alone?\n",
    "    t2,p2 = stats.ttest_ind(combinedData[1],combinedData[2])\n",
    "\n",
    "    # We can do as many t-tests as we want. We will have to adjust the\n",
    "    # alpha-level from 0.05 to 0.05/c, where c is the number of tests\n",
    "    # (comparisons), that's called the \"Bonferroni correction\". \n",
    "\n",
    "    # Even this comparison is significant, even after the Bonferroni correction,\n",
    "    # so we conclude that this observed difference in ratings is not due to\n",
    "    # chance alone. In other words, Matrix 2 is a better movie than Matrix 3. \n",
    "    # Expectation: The p-value will be even lower than 1 vs. 2, because the\n",
    "    # mean difference is larger, but it might not be, because the df will be\n",
    "    # less (fewer people saw M3). The p value comes from the t-value in light of\n",
    "    # the df (because the t-distribution is a family of distributions which\n",
    "    # differs as df - that's a parameter).\n",
    "    t3,p3 = stats.ttest_ind(combinedData[0],combinedData[2])\n",
    "\n",
    "    # Do this with ANOVA - allows to compare more than 2 sample means without \n",
    "    # inflating alpha (from multiple comparisons)\n",
    "    f,p = stats.f_oneway(combinedData[0],combinedData[1],combinedData[2])\n",
    "    \n",
    "    # Nonparametric tests equivalent to t-tests - Mann-Whitney U test:\n",
    "    # Test for comparing medians of ordinal data (such as movie ratings)\n",
    "    # from 2 groups\n",
    "    u1,p1 = stats.mannwhitneyu(combinedData[0],combinedData[1])\n",
    "    u2,p2 = stats.mannwhitneyu(combinedData[0],combinedData[2])\n",
    "    u3,p3 = stats.mannwhitneyu(combinedData[1],combinedData[2])\n",
    "\n",
    "    # Nonparametric tests equivalent to ANOVA - Kruskal-Wallis:\n",
    "    # Same assumptions as above, but for more than 2 groups\n",
    "    h,p = stats.kruskal(combinedData[0],combinedData[1])\n",
    "    \n",
    "    \n",
    "\n",
    "# These are not different people. So we have to do a \"within subjects\"\n",
    "# design (repeated measures) - in other words do a paired samples t-test. \n",
    "# But to do that, we need to do row-wise removal of missing data \n",
    "\n",
    "# 2. Row-wise:\n",
    "elif pruningMode == 2:\n",
    "    # Because our n's are now equal, we can now do a t-test for dependent\n",
    "    # groups (which is much more appropriate, because our data came from the\n",
    "    # *same* people, the groups WERE dependent, we previously inflated df)\n",
    "    t1,p1 = stats.ttest_rel(combinedData[:,0],combinedData[:,1])\n",
    "    df = len(combinedData) - 1\n",
    "    # Df HERE is now n-1, because the t-test for dependent groups first\n",
    "    # converts all scores to differences, then takes ONE mean, so we only\n",
    "    # lose 1 df. Overall, we have much fewer df, than in the independent\n",
    "    # samples t-test.\n",
    "    # The p-value is even lower. How is that possible, given that df is\n",
    "    # lower too? \n",
    "    # In an independent samples t-test individual differences (some people\n",
    "    # just don't like anything, or everything) all goes into the\n",
    "    # denominator, in other words is interpreted as error. That lowers the\n",
    "    # t-value. In a paired-samples t-test, everyone is their own control. So\n",
    "    # the individual differences go away. In english: A paired samples\n",
    "    # t-test is usually much more powerful, even if the df is lower. So you\n",
    "    # should do this one, whenever you can. \n",
    "    t2,p2 = stats.ttest_rel(combinedData[:,1],combinedData[:,2])\n",
    "    t3,p3 = stats.ttest_rel(combinedData[:,0],combinedData[:,2])\n",
    "    \n",
    "    # Let's do an ANOVA instead:\n",
    "    f,p = stats.f_oneway(combinedData[:,0],combinedData[:,1],combinedData[:,2])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "f1ce1853",
   "metadata": {},
   "outputs": [],
   "source": [
    "t1,p1 = stats.ttest_rel(combinedData[:,0],combinedData[:,1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "1d693b97",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(35.36228453531538, 1.8212261420982737e-199)"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t1, p1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b42f8b9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ca9eb65",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
