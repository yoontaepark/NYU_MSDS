{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "k5mRDji1iNsc"
   },
   "source": [
    "# Fall 2022: DS-GA 1011 NLP with Representation Learning\n",
    "## Homework 2\n",
    "## Part 3: Neural Machine Translation (30 pts)\n",
    "In this part, you implement Transformer encoder for Neural Machine Translation (NMT) using a sequence to sequence (seq2seq) model for English to French translation with PyTorch."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ki8Rdu4IiNsd"
   },
   "source": [
    "---\n",
    "### 1 Transformer Encoder (18 pts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "OB4991PPiNse"
   },
   "outputs": [],
   "source": [
    "# Add utilities path\n",
    "import sys\n",
    "\n",
    "path_to_utils = 'pyfiles'\n",
    "sys.path.append(path_to_utils)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "1h61HxKEiNsi"
   },
   "outputs": [],
   "source": [
    "# Import custom modules\n",
    "import global_variables\n",
    "import nmt_dataset\n",
    "import nnet_models_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "juHsWAmriNsl"
   },
   "outputs": [],
   "source": [
    "# Load data\n",
    "import os\n",
    "\n",
    "source_name = 'en'\n",
    "target_name = 'fr'\n",
    "\n",
    "base_saved_models_dir = '.'\n",
    "saved_models_dir = os.path.join(base_saved_models_dir, source_name+'2'+target_name)\n",
    "\n",
    "main_data_path = './data/'\n",
    "\n",
    "path_to_train_data = {'source':main_data_path+'train.'+source_name, \n",
    "                      'target':main_data_path+'train.'+target_name}\n",
    "path_to_val_data = {'source': main_data_path+'valid.'+source_name, \n",
    "                      'target':main_data_path+'valid.'+target_name}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "4ZISJFayiNso"
   },
   "outputs": [],
   "source": [
    "saved_language_model_dir = os.path.join(saved_models_dir, 'lang_obj')\n",
    "\n",
    "dataset_dict = {'train': nmt_dataset.LanguagePair(source_name = source_name, target_name=target_name, \n",
    "                    filepath = path_to_train_data, \n",
    "                    lang_obj_path = saved_language_model_dir,\n",
    "                     minimum_count = 1), \n",
    "\n",
    "                'val': nmt_dataset.LanguagePair(source_name = source_name, target_name=target_name, \n",
    "                    filepath = path_to_val_data, \n",
    "                    lang_obj_path = saved_language_model_dir,\n",
    "                    minimum_count = 1)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "9F04tskaiNsr"
   },
   "outputs": [],
   "source": [
    "MAX_LEN = int(dataset_dict['train'].main_df['source_len'].quantile(0.9999)) # 32\n",
    "batchSize = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "-5GP1oyqiNsv"
   },
   "outputs": [],
   "source": [
    "from functools import partial\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "dataloader_dict = {'train': DataLoader(dataset_dict['train'], batch_size = batchSize, \n",
    "                            collate_fn = partial(nmt_dataset.vocab_collate_func, MAX_LEN=MAX_LEN),\n",
    "                            shuffle = True, num_workers=0), \n",
    "                    'val': DataLoader(dataset_dict['val'], batch_size = batchSize, \n",
    "                            collate_fn = partial(nmt_dataset.vocab_collate_func, MAX_LEN=MAX_LEN),\n",
    "                            shuffle = True, num_workers=0) }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "l_T7Fi87iNsy"
   },
   "outputs": [],
   "source": [
    "# Configuration\n",
    "source_lang_obj = dataset_dict['train'].source_lang_obj\n",
    "target_lang_obj = dataset_dict['train'].target_lang_obj\n",
    "\n",
    "source_vocab = dataset_dict['train'].source_lang_obj.n_words;\n",
    "target_vocab = dataset_dict['train'].target_lang_obj.n_words;\n",
    "hidden_size = 512\n",
    "enc_layers = 1\n",
    "lr = 0.25; # try 0.01 later\n",
    "longest_label = 1;\n",
    "gradient_clip = 0.3;\n",
    "use_cuda = True\n",
    "\n",
    "num_epochs = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0bghnW3YiNs2"
   },
   "source": [
    "#### 1.1 Encoder (9 pts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add library / configuration for positional embeddings\n",
    "import torch\n",
    "from torch import nn\n",
    "from math import sqrt, sin, cos\n",
    "\n",
    "## add config\n",
    "d_model = 512\n",
    "n_heads = 2\n",
    "seq_len = 512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add transformer as encoder in seq2seq model\n",
    "\n",
    "# code below can help you to start it, but feel free to start from scratch\n",
    "\n",
    "class EncoderTransformer(nn.Module):\n",
    "    def __init__(self, n_vocab, d_model, seq_len, enc_layers, n_heads):\n",
    "\n",
    "        super().__init__()\n",
    "        \n",
    "        # you need to add more things here\n",
    "        self.embed = nn.Embedding(n_vocab, d_model)\n",
    "        self.pos_embed = nn.Embedding(seq_len, d_model) # sinusoidal embedding\n",
    "        \n",
    "\n",
    "        # Relative positional embeddings taken from https://arxiv.org/pdf/1706.03762.pdf.\n",
    "        self.pos_embed.requires_grad = False\n",
    "        embeddings = self.pos_embed.weight\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for pos in range(seq_len):\n",
    "                for idx in range(d_model // 2):\n",
    "                    embeddings[pos, 2 * idx] = sin(pos / 10000**(2 * idx / d_model))\n",
    "                    embeddings[pos, 2 * idx + 1] = cos(pos / 10000**(2 * idx / d_model))\n",
    "\n",
    "        encoder_layer = nn.TransformerEncoderLayer(d_model, n_heads)\n",
    "        self.transformer = nn.TransformerEncoder(encoder_layer, num_layers=enc_layers)\n",
    "\n",
    "        \n",
    "    def forward(self, text_vec):\n",
    "        # some helpful directions below, check the MLM lab for more details\n",
    "        _, seq_len = text_vec.size()\n",
    "        embeddings = self.embed(text_vec)\n",
    "        \n",
    "        positions = torch.arange(seq_len, device=text_vec.device)\n",
    "        pos_embeddings = self.pos_embed(positions).unsqueeze(dim=0)\n",
    "        \n",
    "#         print('size check: ', embeddings.size(), pos_embeddings.size())\n",
    "        embeddings = embeddings + pos_embeddings  # apply pos embedding\n",
    "        \n",
    "        output = self.transformer(embeddings)\n",
    "#         print('output:', output, output.shape)\n",
    "\n",
    "        hidden_encoder = torch.sum(output,1,True).permute(1,0,2)\n",
    "#         print('hidden:', hidden_encoder, hidden_encoder.shape)\n",
    "        \n",
    "        return output, hidden_encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[-0.9330, -0.1128,  0.9978, -0.4210],\n",
      "         [ 0.1949,  0.4050,  0.0911, -0.1466],\n",
      "         [ 1.8391,  2.0360, -0.5387,  0.0095]]]) torch.Size([1, 3, 4])\n",
      "\n",
      "tensor([[[-0.9330, -0.1128,  0.9978, -0.4210]],\n",
      "\n",
      "        [[ 0.1949,  0.4050,  0.0911, -0.1466]],\n",
      "\n",
      "        [[ 1.8391,  2.0360, -0.5387,  0.0095]]]) torch.Size([3, 1, 4])\n",
      "\n",
      "tensor([[[ 1.1009,  2.3282,  0.5502, -0.5581]]]) torch.Size([1, 1, 4])\n",
      "\n",
      "tensor([[[ 1.1009,  2.3282,  0.5502, -0.5581]]]) torch.Size([1, 1, 4])\n",
      "\n"
     ]
    }
   ],
   "source": [
    "a = torch.randn(1,3,4) \n",
    "print(a, a.shape)\n",
    "print()\n",
    "\n",
    "b = a.permute(1,0,2)\n",
    "print(b, b.shape)\n",
    "print()\n",
    "\n",
    "c = torch.sum(b, 0, True)\n",
    "print(c, c.shape)\n",
    "print()\n",
    "\n",
    "d = torch.sum(a, 1, True)\n",
    "print(d, d.shape)\n",
    "print()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = EncoderTransformer(n_vocab=source_vocab, d_model=d_model, seq_len=seq_len, \\\n",
    "                             enc_layers=enc_layers, n_heads=n_heads)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xcUYkz_RiNs9"
   },
   "source": [
    "#### 1.2 Decoder(s) (9 pts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {
    "id": "OT_JZXWeiNs9"
   },
   "outputs": [],
   "source": [
    "# Basic RNN decoder (no attention)\n",
    "decoder_rnn_1 = nnet_models_new.DecoderRNN(target_vocab, hidden_size, enc_layers)\n",
    "\n",
    "full_model_1 = nnet_models_new.seq2seq(encoder, decoder_rnn_1,\n",
    "                              lr = lr, \n",
    "                              use_cuda = use_cuda, \n",
    "                              hiddensize = hidden_size, \n",
    "                              numlayers = enc_layers, \n",
    "                              target_lang=dataset_dict['train'].target_lang_obj,\n",
    "                              longest_label = longest_label,\n",
    "                              clip = gradient_clip)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {
    "id": "U6DmOcLViNtB"
   },
   "outputs": [],
   "source": [
    "# RNN Decoder with Encoder attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {
    "id": "szrb9vkiiNtE"
   },
   "outputs": [],
   "source": [
    "# RNN Decoder with Encoder & Self attention"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "u_dYn8C_iNtH"
   },
   "source": [
    "#### Training & Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Reasonable range:\n",
    "Basic RNN decoder (no attention): around 10\n",
    "RNN decoder with encoder attention: around 15\n",
    "RNN decoder with encoder attention and self-attention: around 25\n",
    "'''\n",
    "\n",
    "from tqdm import notebook\n",
    "import time\n",
    "\n",
    "def train_model(dataloader, nmt, num_epochs=20, val_every=1, saved_model_path = '.', enc_type ='rnn'):\n",
    "    \n",
    "    # we need to plot loss and blew for the future quesitons \n",
    "    # create an emply list for both loss and bleu score\n",
    "    train_loss_list, train_bleu_list = [], []\n",
    "    val_loss_list, val_bleu_list = [], []\n",
    "    best_bleu = -1\n",
    "    \n",
    "    # start epoch\n",
    "    for epoch in range(num_epochs):\n",
    "\n",
    "        start = time.time()\n",
    "        train_loss = 0\n",
    "\n",
    "        print('Epoch: [{}/{}]'.format(epoch, num_epochs))\n",
    "        \n",
    "        ###\n",
    "        # training part\n",
    "        for i, data in notebook.tqdm(enumerate(dataloader['train'])):\n",
    "            _, curr_loss = nmt.train_step(data);\n",
    "            train_loss += curr_loss\n",
    "        \n",
    "        ## loss\n",
    "        train_loss = train_loss / len(dataloader['train']) \n",
    "        print('training loss and bleu score:')\n",
    "        print(\"epoch {} loss = {}, time = {}\".format(epoch, train_loss,\n",
    "                                                        time.time() - start))\n",
    "        \n",
    "        # bleu score\n",
    "        train_bleu_score = nmt.get_bleu_score(dataloader['train'])\n",
    "        print('training blue:', train_bleu_score)\n",
    "        print()\n",
    "        \n",
    "        # save results to plot \n",
    "        train_loss_list.append(train_loss)\n",
    "        train_bleu_list.append(train_bleu_score)\n",
    "        \n",
    "        sys.stdout.flush()\n",
    "        \n",
    "        ###\n",
    "        # validation part\n",
    "        # initialize loss and set the model to eval mode\n",
    "        val_loss = 0\n",
    "        nmt.eval()\n",
    "        \n",
    "        # this is validation set, so no calculation with no grad\n",
    "        with torch.no_grad():\n",
    "            for i, data in notebook.tqdm(enumerate(dataloader['val'])):\n",
    "                _, curr_loss = nmt.train_step(data);\n",
    "                val_loss += curr_loss\n",
    "                \n",
    "            ## loss\n",
    "            val_loss = val_loss / len(dataloader['val']) \n",
    "            val_loss_list.append(val_loss)\n",
    "            print('valiation loss and bleu score:')\n",
    "            print(\"epoch {} loss = {}, time = {}\".format(epoch, val_loss,\n",
    "                                                            time.time() - start))     \n",
    "        \n",
    "        if epoch%val_every == 0:\n",
    "            val_bleu_score = nmt.get_bleu_score(dataloader['val']);\n",
    "            val_bleu_list.append(val_bleu_score)\n",
    "            print('validation bleu: ', val_bleu_score)\n",
    "            sys.stdout.flush()\n",
    "\n",
    "            nmt.scheduler_step(val_bleu_score);\n",
    "\n",
    "            if val_bleu_score > best_bleu:\n",
    "                best_bleu = val_bleu_score\n",
    "#                 save_models(nmt, saved_model_path, enc_type);\n",
    "\n",
    "        print('='*50)\n",
    "\n",
    "    print(\"Training completed. Best BLEU is {}\".format(best_bleu))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ccb9474ab5c24459af8ec137af2e8242",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [0/20]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d409af42c8464543874f78c9bd5aa64c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [185], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataloader_dict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfull_model_1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[43m                  \u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m                  \u001b[49m\u001b[43msaved_model_path\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43msaved_models_dir\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m                  \u001b[49m\u001b[43menc_type\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mrnn_test\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn [184], line 29\u001b[0m, in \u001b[0;36mtrain_model\u001b[0;34m(dataloader, nmt, num_epochs, val_every, saved_model_path, enc_type)\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[38;5;66;03m###\u001b[39;00m\n\u001b[1;32m     27\u001b[0m \u001b[38;5;66;03m# training part\u001b[39;00m\n\u001b[1;32m     28\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, data \u001b[38;5;129;01min\u001b[39;00m notebook\u001b[38;5;241m.\u001b[39mtqdm(\u001b[38;5;28menumerate\u001b[39m(dataloader[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m'\u001b[39m])):\n\u001b[0;32m---> 29\u001b[0m     _, curr_loss \u001b[38;5;241m=\u001b[39m \u001b[43mnmt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m;\n\u001b[1;32m     30\u001b[0m     train_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m curr_loss\n\u001b[1;32m     32\u001b[0m \u001b[38;5;66;03m## loss\u001b[39;00m\n",
      "File \u001b[0;32m~/★NYU_Class/2022_Fall/dsga1011/hw/hw2-oct24/pyfiles/nnet_models_new.py:418\u001b[0m, in \u001b[0;36mseq2seq.train_step\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    416\u001b[0m scores \u001b[38;5;241m=\u001b[39m decoder_output\u001b[38;5;241m.\u001b[39mview(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, decoder_output\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m))\n\u001b[1;32m    417\u001b[0m loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcriterion(scores, ys\u001b[38;5;241m.\u001b[39mview(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m))\n\u001b[0;32m--> 418\u001b[0m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    419\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mupdate_params()\n\u001b[1;32m    421\u001b[0m _max_score, predictions \u001b[38;5;241m=\u001b[39m decoder_output\u001b[38;5;241m.\u001b[39mmax(\u001b[38;5;241m2\u001b[39m)\n",
      "File \u001b[0;32m~/opt/miniconda3/envs/torch/lib/python3.9/site-packages/torch/_tensor.py:396\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    387\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    388\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    389\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    390\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    394\u001b[0m         create_graph\u001b[38;5;241m=\u001b[39mcreate_graph,\n\u001b[1;32m    395\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs)\n\u001b[0;32m--> 396\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/miniconda3/envs/torch/lib/python3.9/site-packages/torch/autograd/__init__.py:173\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    168\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    170\u001b[0m \u001b[38;5;66;03m# The reason we repeat same the comment below is that\u001b[39;00m\n\u001b[1;32m    171\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    172\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 173\u001b[0m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    174\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    175\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train_model(dataloader_dict, full_model_1, \n",
    "                  num_epochs = num_epochs, \n",
    "                  saved_model_path = saved_models_dir, \n",
    "                  enc_type = 'rnn_test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "id": "N1-h6PlgiNtI"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HLef3aD5iNtM"
   },
   "source": [
    "---\n",
    "### 2 Attention visualization (12 pts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mVcysNCtiNtN"
   },
   "outputs": [],
   "source": [
    "# Model was trained in ~2 hours, i.e. you can expect attention maps\n",
    "# to look quite 'hard' (less soft spreading) i.e. attending to some particular token in the input"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "hw2-part3-nmt.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3.9 (pytorch)",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
